{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load packages and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to avoid OOM errors in the form of \"UnimplementedError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [[node model/conv2d/Conv2D (defined at :6) ]] [Op:__inference_distributed_function_7653]\"\n",
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # https://stackoverflow.com/a/61786189\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "from matplotlib import pyplot as plt\n",
    "import myloginpath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Configure access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 2\n"
     ]
    }
   ],
   "source": [
    "print('Num GPUs Available:', len(tf.config.list_physical_devices('GPU')))\n",
    "physical_devices = tf.config.list_physical_devices('GPU') # list of physical devices visible to the host runtime\n",
    "# specifies which PhysicalDevice objects are visible to the runtime. TF will only allocate memory and place operations on visible physical devices\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "\n",
    "try: \n",
    "    for gpu in physical_devices:\n",
    "        # If memory growth is enabled for a PhysicalDevice, the runtime initialization will not allocate all memory on the device. \n",
    "        # Memory growth cannot be configured on a PhysicalDevice with virtual devices configured.\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Set the virtual device configuration for a PhysicalDevice. memory_limit in MB\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu, [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=20_000)]) \n",
    "except: \n",
    "    print('Invalid device or cannot modify virtual devices once initialized.', flush=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Using this strategy will place any variables created in its scope on the specified device. \n",
    "# Input distributed through this strategy will be prefetched to the specified device. \n",
    "# Moreover, any functions called via strategy.run will also be placed on the specified device as well.\n",
    "\n",
    "#TODO why are we doing this?\n",
    "strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters to connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mysqlSettings = myloginpath.parse('client', path='/tf/.mylogin.cnf')\n",
    "mysqlSettings['database'] = 'sensor_data_schema'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global parameters (Make sure to choose a unique name for each run!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelName = 'test_12Mparam'\n",
    "path = '/tf/home'\n",
    "tensorboardLogFolder = f'{path}/logs'\n",
    "checkpointFolder = f'{path}/checkpoints/{modelName}/'\n",
    "#confMatFolder = f'{path}/confusion_matrix/{modelName}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetList = [\n",
    "    #POLLEN DATASETS --------------------------------------------------------\n",
    "    ('alnus', 3990, '11ea8493-7107-8db4-9bf7-ae7b87f820b4'),                 # 0alnus 'alnus_20200220_p5_1_benoit' 3990\n",
    "    ('alnus', 4966, '11ea847a-f995-790c-830f-ae7b87f820b4'),                 # 0alnus 'alnus_20200218_p2_1_benoit' 4966\n",
    "    ('alnus', 3474, '11ea8475-957e-347c-985a-ae7b87f820b4'),                 # 0alnus 'alnus_20200214_p4_1_benoit' 3474 TOTAL ALNUS=12'430\n",
    "    ('betula', 5770, '11ea8897-f50e-66a2-9876-ae7b87f820b4'),                # 1betula 'betula_20200406_p2_1_benoit' 5770\n",
    "    ('betula', 6533, '11ea8632-18ed-7210-985a-ae7b87f820b4'),                # 1betula 'betula_20200407_p4_2_benoit' 6533\n",
    "    ('betula', 2173, '11ea8632-1eb2-2452-bc84-ae7b87f820b4'),                # 1betula 'betula_20200406_p4_1_benoit' 2173 TOTAL BETULA=14'476\n",
    "    ('carpinus', 643, '11ea8f77-4ee3-aef4-b330-ae7b87f820b4'),               # 2carpinus 'carpinus_20200319_p5_2_fiona' 643\n",
    "    ('carpinus', 664, '11ea8f6d-3e75-9fe6-b46e-ae7b87f820b4'),               # 2carpinus 'carpinus_20200319_p2_2_fiona' 664\n",
    "    ('carpinus', 545, '11ea8f6d-1562-211a-8192-ae7b87f820b4'),               # 2carpinus 'carpinus_20200319_p2_3_fiona' 545\n",
    "    ('carpinus', 395, '11ea8f6c-b78c-d076-a542-ae7b87f820b4'),               # 2carpinus 'carpinus_20200319_p4_2_fiona' 395 TOTAL CARPINUS=2'247\n",
    "    ('corylus', 3736, '11ea8498-b729-d4e6-bc84-ae7b87f820b4'),               # 3corylus 'corylus_20200225_p2_2_benoit' 3736\n",
    "    ('corylus', 500, '11ea8498-b083-cb92-a1a5-ae7b87f820b4'),                # 3corylus 'corylus_20200225_p2_1_benoit' 500\n",
    "    ('corylus', 3578, '11ea8498-afa9-cec4-a877-ae7b87f820b4'),               # 3corylus 'corylus_20200225_p5_1_benoit' 3578 TOTAL CORYLUS=7'814\n",
    "    ('cupressus', 421, '11ea8fa9-6c12-723a-b3dd-ae7b87f820b4'),              # 4cupressus 'cupressus_20200317_p5_1_fiona' 421\n",
    "    ('cupressus', 2340, '11ea8fa8-fafa-aeb4-ac46-ae7b87f820b4'),             # 4cupressus 'cupressus_20200317_p2_1_fiona' 2340\n",
    "    ('cupressus', 583, '11ea8fa8-d163-dce2-b1cb-ae7b87f820b4'),              # 4cupressus 'cupressus_20200317_p4_1_fiona' 583 TOTAL CUPRESSUS=3'344\n",
    "    ('fagus', 2759, '11ea8636-313b-a6e4-a69e-ae7b87f820b4'),                 # 5fagus 'fagus_20200413_p4_1_benoit' 2759\n",
    "    ('fagus', 3410, '11ea8635-ef91-6ab2-a877-ae7b87f820b4'),                 # 5fagus 'fagus_20200407_p2_1_benoit' 3410\n",
    "    ('fagus', 4143, '11ea8635-eb18-6ee0-9876-ae7b87f820b4'),                 # 5fagus 'fagus_20200413_p5_1_benoit' 4143 TOTAL FAGUS=10'312\n",
    "    ('fraxinus', 5703, '11ea857e-7bc5-60a0-842e-ae7b87f820b4'),              # 6fraxinus 'fraxinus_20200402_p5_2_benoit' 5703\n",
    "    ('fraxinus', 2621, '11ea857b-3d52-9034-830f-ae7b87f820b4'),              # 6fraxinus 'fraxinus_20200330_p4_1_benoit' 2621\n",
    "    ('fraxinus', 1712, '11ea857b-150e-c372-bc84-ae7b87f820b4'),              # 6fraxinus 'fraxinus_20200330_p2_1_benoit' 1712 TOTAL FRAXINUS=10'036\n",
    "    ('pinaceae', 1826, '11ea8af3-c533-f39e-8b25-ae7b87f820b4'),              # 7pinaceae 'picea_20200423_p2_1_fiona' 1826\n",
    "    ('pinaceae', 2375, '11ea8af1-91fc-9a46-8b25-ae7b87f820b4'),              # 7pinaceae 'picea_20200423_p4_1_fiona' 2375\n",
    "    ('pinaceae', 1969, '11ea8af0-83dc-6d66-b06c-ae7b87f820b4'),              # 7pinaceae 'picea_20200423_p5_1_fiona' 1969\n",
    "    ('pinaceae', 3403, '11ea863d-acf6-0ade-985a-ae7b87f820b4'),              # 7pinaceae 'pinus_20200421_p5_1_benoit' 3403\n",
    "    ('pinaceae', 8582, '11ea863c-2449-be52-8814-ae7b87f820b4'),              # 7pinaceae 'pinus_20200421_p2_1_benoit' 8582 TOTAL PINACEAE=18'155\n",
    "    ('platanus', 5603, '11ea8b83-25c9-8194-90d1-ae7b87f820b4'),              # 8platanus 'platanus_20200417_p4_1_benoit' 5603\n",
    "    ('platanus', 5544, '11ea8881-3721-9aa8-a907-ae7b87f820b4'),              # 8platanus 'platanus_20200417_p2_1_benoit' 5544 TOTAL PLATANUS=11'147\n",
    "    ('poaceae', 1229, '11ea990f-ee01-8334-b3dd-ae7b87f820b4'),               # 9poaceae 'gram_20200518_p2_1_benoit' 1229\n",
    "    ('poaceae', 1508, '11ea990c-b2bc-fe96-b46e-ae7b87f820b4'),               # 9poaceae 'gram_20200518_p5_1_benoit' 1508  TOTAL POACEAE inital=4'909\n",
    "    ('poaceae', 5895, '11eb5fd9-961a-313e-ac56-ae7b87f820b4'),               # 9poaceae 'POCclean_cynosurus_20200520_p4_1_fiona' 5895\n",
    "    ('poaceae', 6248, '11eb5fd9-dd36-0a20-88f3-ae7b87f820b4'),               # 9poaceae 'POCclean_cynosurus_20200520_p2_1_' 6248\n",
    "    ('poaceae', 3110, '11ebe542-660e-0206-80be-ae7b87f820b4'),               # 9poaceae 'poaceae_dactylis_fresh_p19_2021_tri_Nina' 3110\n",
    "    ('poaceae', 1127, '11eb5fc3-03fa-6da2-8b42-ae7b87f820b4'),               # 9poaceae 'POCclean_dactylis_20200518_p4_1' 1127\n",
    "    ('poaceae', 1377, '11ebe540-187e-9a0c-b0e2-ae7b87f820b4'),               # 9poaceae 'poaceae_trisetum_fresh_p19_2021_tri_Nina' 1377\n",
    "    ('populus', 657, '11ea8893-edfb-ca84-a877-ae7b87f820b4'),                # 10populus 'populus_20200327_p5_1_benoit' 657\n",
    "    ('populus', 508, '11ea84a0-e89b-43b8-a69e-ae7b87f820b4'),                # 10populus 'populus_20200327_p2_benoit' 508\n",
    "    ('populus', 2913, '11ea84a0-a2f0-ab8c-a877-ae7b87f820b4'),               # 10populus 'populus_20200327_p4_benoit' 2913 TOTAL POPULUS=4'078\n",
    "    ('quercus', 3824, '11ea863e-1fea-0f7c-a1a5-ae7b87f820b4'),               # 11quercus 'quercus_20200421_p4_1_benoit' 3824\n",
    "    ('quercus', 4768, '11ea863e-1b86-8226-a1a5-ae7b87f820b4'),               # 11quercus 'quercus_20200421_p2_1_benoit' 4768\n",
    "    ('quercus', 2519, '11ea863d-f388-a038-a1a5-ae7b87f820b4'),               # 11quercus 'quercus_20200421_p5_1_benoit' 2519 TOTAL QUERCUS=11'111\n",
    "    ('taxus', 4872, '11ea8477-cede-e7dc-897d-ae7b87f820b4'),                 # 12taxus 'taxus_20200218_p4_1_benoit' 4872\n",
    "    ('taxus', 5593, '11ea8477-b584-b690-830f-ae7b87f820b4'),                 # 12taxus 'taxus_20200218_p2_1_benoit' 5593\n",
    "    ('taxus', 3411, '11ea8494-33a5-2e4e-bc84-ae7b87f820b4'),                 # 12taxus 'taxus_20200220_p5_1_benoit' 3411 TOTAL TAXUS=13'876\n",
    "    ('ulmus', 3289, '11ea849c-df8f-d95e-897d-ae7b87f820b4'),                 # 13ulmus 'ulmus_20200311_p4_2_benoit' 3289\n",
    "    ('ulmus', 2392, '11ea849c-db7b-2170-8b0f-ae7b87f820b4'),                 # 13ulmus 'ulmus_20200311_p2_2_benoit' 2392\n",
    "    ('ulmus', 4844, '11ea849a-0e25-4018-8814-ae7b87f820b4'),                 # 13ulmus 'ulmus_20200304_p5_1_benoit' 4844 TOTAL ULMUS=10'525\n",
    "    ## SPORES DATASETS ------------------------------------------------------\n",
    "    ('alternaria solani', 2767, '11ebf9db-f2e9-98cc-bc67-ae7b87f820b4'),     # 14Alternaria solani 'alternaria_solani_sophie_clean' event counts 2767\n",
    "    ('fusarium graminearum', 25054, '11ec01b9-d571-ea8e-b7e1-ae7b87f820b4'), # 15Fusarium graminearum 'fusarium_graminearum_p1' event count 25054\n",
    "    ## WATER DROPPLETS (WD) DATASETS ----------------------------------------\n",
    "    ('rain', 389, '11ebe542-f782-c172-bf10-ae7b87f820b4'),                   # 16Rain 'P5_Payerne_Rain_28_04' event counts 389\n",
    "    ('rain', 2786, '11ebeabd-e224-d5c4-8b63-ae7b87f820b4'),                  # 16Rain 'P5_Payerne_Rain_30_04_AM' event counts 2786\n",
    "    ('rain', 3179, '11ebedec-0da5-47ac-8066-ae7b87f820b4'),                  # 16Rain 'P5_Payerne_Rain_30_04_PM' event counts 3179\n",
    "    ('rain', 7691, '11ebee15-1fea-4c68-9cd6-ae7b87f820b4'),                  # 16Rain 'P16_Locarno_Rain_29_04' event counts 7691 TOTAL PLUIE = 14045\n",
    "    ## IBERULITES DATASETS --------------------------------------------------\n",
    "    ('iberulite', 190, '11ec6179-fde0-042c-adac-ae7b87f820b4'),              # 17Iberulite 'P4_iberulites_06022021_clean' event counts 190\n",
    "    ('iberulite', 183, '11ec5821-b371-c3dc-8359-ae7b87f820b4'),              # 17Iberulite 'P5_iberulites_06022021_clean' event counts 183\n",
    "    ('iberulite', 66, '11ec617a-fb8b-e3f2-80fb-ae7b87f820b4'),               # 17Iberulite 'P4_saharan_dust_april2021_clean' event counts 66\n",
    "    ('iberulite', 556, '11ec5832-4fee-03b4-8561-ae7b87f820b4'),              # 17Iberulite 'P5_saharan_dust_april2021_clean' event counts 117 TOTAL IBERULITE = 556\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunksize = 256 # How many events should be used per dataset. TF will train on them for x epochs before going to the next chunk of data. Choose size according to your hardware (ram, gpu, gpu-memory)\n",
    "n_prefetch = 2 # How many batches should be cached in the background.\n",
    "batchsize_per_replica = 64 \n",
    "batchsize = batchsize_per_replica * strategy.num_replicas_in_sync # number of samples processed before the model is updated\n",
    "epochs = 2 # number of complete passes through the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_names = set(map(lambda i: i[0], datasetList)) # set of class names\n",
    "target_ids_mapping = {id: list(target_names).index(label) for id, (label, _, _) in enumerate(datasetList)} # mapping of dataset_id: class name\n",
    "num_classes = len(target_names) # number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "tags": []
   },
   "source": [
    "from chgData import DatasetLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "ds_loader = DatasetLoader(datasetList, num_classes, mysqlSettings, chunksize, batchsize, n_prefetch)\n",
    "train_set, val_set, test_set = ds_loader.load_all()\n",
    "#next(iter(train_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessingFunc import load_blob, process_waves, filter_blur, filter_crop\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "img_preprocessing = lambda img0,img1: process_waves(\n",
    "                                        *filter_crop(\n",
    "                                            *filter_blur(\n",
    "                                                *load_blob(img0,img1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building testset\n"
     ]
    }
   ],
   "source": [
    "# swisens way\n",
    "from swisensDataFunc import init_sets as swisens_init_sets, get_train as swisens_get_train\n",
    "itList, test_set = swisens_init_sets(\n",
    "    datasetList, \n",
    "    batchsize, \n",
    "    chunksize, \n",
    "    n_prefetch, \n",
    "    mysqlSettings, \n",
    "    target_ids_mapping, \n",
    "    num_classes, \n",
    "    img_preprocessing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(nClasses, with_fluorescence=False, n_fl_configs=1,strategy=strategy):\n",
    "\n",
    "    in_img0 = tf.keras.layers.Input((200,200,1))\n",
    "    in_img1 = tf.keras.layers.Input((200,200,1))\n",
    "\n",
    "    # If you want to train a model including fluorescence, you need to include these inputs in your model\n",
    "    if with_fluorescence:\n",
    "        in_fl_avg = tf.keras.layers.Input((n_fl_configs*6, 1))\n",
    "        in_fl_pha = tf.keras.layers.Input((n_fl_configs*6, 1))\n",
    "        in_fl_corrMag = tf.keras.layers.Input((n_fl_configs*6, 1))\n",
    "\n",
    "\n",
    "    #Image Processing\n",
    "    path1 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(in_img0)\n",
    "    path1 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path1)\n",
    "    path1 = tf.keras.layers.Dropout(0.1)(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path1)\n",
    "    path1 = tf.keras.layers.Dropout(0.1)(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path1)\n",
    "    path1 = tf.keras.layers.Dropout(0.1)(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='valid')(path1)\n",
    "    path1 = tf.keras.layers.Dropout(0.1)(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path1)\n",
    "    path1 = tf.keras.layers.Dropout(0.1)(path1)\n",
    "\n",
    "    #path1 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path1)\n",
    "    #path1 = tf.keras.layers.Dropout(0.3)(path1)\n",
    "    #path1 = tf.keras.layers.Dropout(0.4)(path1)\n",
    "    path2 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(in_img1)\n",
    "    path2 = tf.keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path2)\n",
    "    path2 = tf.keras.layers.Dropout(0.1)(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path2)\n",
    "    path2 = tf.keras.layers.Dropout(0.1)(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path2)\n",
    "    path2 = tf.keras.layers.Dropout(0.1)(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='valid')(path2)\n",
    "    path2 = tf.keras.layers.Dropout(0.1)(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path2)\n",
    "    path2 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path2)\n",
    "    path2 = tf.keras.layers.Dropout(0.1)(path2)\n",
    "\n",
    "    #path2 = tf.keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path2)\n",
    "    #path2 = tf.keras.layers.Dropout(0.3)(path2)\n",
    "\n",
    "    path1Flat = tf.keras.layers.Flatten()(path1)\n",
    "    path2Flat = tf.keras.layers.Flatten()(path2)\n",
    "\n",
    "    # FL Processing\n",
    "    if with_fluorescence:\n",
    "        fl_avg_path = processFlInput(in_fl_avg)\n",
    "        fl_pha_path = processFlInput(in_fl_pha)\n",
    "        fl_corrMag_path = processFlInput(in_fl_corrMag)\n",
    "        path = tf.keras.layers.Concatenate()(\n",
    "            [path1Flat, path2Flat, fl_avg_path, fl_pha_path, fl_corrMag_path]\n",
    "        )\n",
    "    else:\n",
    "        path = tf.keras.layers.Concatenate()([path1Flat, path2Flat])\n",
    "\n",
    "    #Densely(fully)-connected layer\n",
    "    path = tf.keras.layers.Dense(256)(path)\n",
    "    path = tf.keras.layers.Dropout(0.2)(path)\n",
    "    path = tf.keras.layers.Dense(128)(path)\n",
    "    path = tf.keras.layers.Dropout(0.2)(path)\n",
    "    #Densely(fully)-connected layer\n",
    "    path = tf.keras.layers.Dense(nClasses)(path)\n",
    "    #Softmax activation fct\n",
    "    output = tf.keras.layers.Softmax()(path)\n",
    "\n",
    "    # If we work with fluorescence, we need to add all the inputs to the final model\n",
    "    if with_fluorescence:\n",
    "        model = tf.keras.Model(\n",
    "            inputs=[in_img0, in_img1, in_fl_avg, in_fl_pha, in_fl_corrMag],\n",
    "            outputs=output\n",
    "        )\n",
    "    else:\n",
    "        model = tf.keras.Model(inputs=[in_img0, in_img1], outputs=output)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = tf.keras.callbacks.TensorBoard(log_dir=f\"{tensorboardLogFolder}/{modelName}\")\n",
    "saver = tf.keras.callbacks.ModelCheckpoint(filepath=checkpointFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # Instantiate an optimizer to train the model.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    # Instantiate a loss function.\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False) # remove the from_logits=True if you simply call model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Model is built:\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 200, 200, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 200, 200, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 200, 200, 64  1664        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 200, 200, 64  1664        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 200, 200, 64  102464      ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 200, 200, 64  102464      ['conv2d_13[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 100, 100, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 100, 100, 64  0          ['conv2d_14[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100, 100, 64  0           ['max_pooling2d[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 100, 100, 64  0           ['max_pooling2d_5[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 100, 100, 64  36928       ['dropout[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 100, 100, 64  36928       ['dropout_5[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 100, 100, 64  36928       ['conv2d_2[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 100, 100, 64  36928       ['conv2d_15[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 50, 50, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 50, 50, 64)  0           ['conv2d_16[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50, 50, 64)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 50, 50, 64)   0           ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 50, 50, 128)  73856       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 50, 50, 128)  73856       ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 50, 50, 128)  147584      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 50, 50, 128)  147584      ['conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 50, 50, 128)  147584      ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 50, 50, 128)  147584      ['conv2d_18[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 128)  0          ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPooling2D)  (None, 25, 25, 128)  0          ['conv2d_19[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 25, 25, 128)  0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 25, 25, 128)  0           ['max_pooling2d_7[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 25, 25, 256)  295168      ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 25, 25, 256)  295168      ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 25, 25, 256)  590080      ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 25, 25, 256)  590080      ['conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 25, 25, 256)  590080      ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 25, 25, 256)  590080      ['conv2d_21[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 256)  0          ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 12, 12, 256)  0          ['conv2d_22[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 12, 12, 256)  0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 12, 12, 256)  0           ['max_pooling2d_8[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 12, 12, 256)  590080      ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 12, 12, 256)  590080      ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 12, 12, 256)  590080      ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 12, 12, 256)  590080      ['conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 12, 12, 256)  590080      ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 12, 12, 256)  590080      ['conv2d_24[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 6, 6, 256)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 6, 6, 256)   0           ['conv2d_25[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 6, 6, 256)    0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 6, 6, 256)    0           ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 9216)         0           ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 9216)         0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 18432)        0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          4718848     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 256)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          32896       ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 18)           2322        ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " softmax (Softmax)              (None, 18)           0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,339,218\n",
      "Trainable params: 12,339,218\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    print('Building model...', flush=True)\n",
    "    model = get_model(num_classes, strategy=strategy)\n",
    "    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "    print('Model is built:', flush=True)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    train_acc_metric = tf.keras.metrics.CategoricalAccuracy() # SparseCategoricalAccuracy if using old code\n",
    "    val_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,), flush=True)\n",
    "    \n",
    "    if epoch > 0:\n",
    "        print('Shuffle the dataset and re-create batches for training...', flush=True)\n",
    "        #train_set.unbatch().shuffle().batch(batchsize) # TODO\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    print(\"1\")\n",
    "    train_set = swisens_get_train(itList, batchsize, num_classes) # TODO\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_set):\n",
    "        print(\"2\")\n",
    "\n",
    "        # Open a GradientTape to record the operations run during the forward pass, which enables auto-differentiation.\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            # Run the forward pass of the layer.\n",
    "            # The operations that the layer applies to its inputs are going to be recorded on the GradientTape.\n",
    "            logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
    "\n",
    "            # Compute the loss value for this minibatch.\n",
    "            loss_value = loss_fn(y_batch_train, logits)\n",
    "\n",
    "        # Use the gradient tape to automatically retrieve the gradients of the trainable variables with respect to the loss.\n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "\n",
    "        # Run one step of gradient descent by updating the value of the variables to minimize the loss.\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "        # Update training metric.\n",
    "        train_acc_metric.update_state(y_batch_train, logits)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\"Training loss (for one batch) at step %d: %.4f\" % (step, float(loss_value)))\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batchsize))\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_set:\n",
    "        val_logits = model(x_batch_val, training=False)\n",
    "        # Update val metrics\n",
    "        val_acc_metric.update_state(y_batch_val, val_logits)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# old training code\n",
    "datasetCounter = 0\n",
    "bestAccuracy = 0.00\n",
    "bestValAccuracy = 0.00\n",
    "confusion_final = np.zeros((num_classes,num_classes))\n",
    "\n",
    "while True:\n",
    "    # Reset confusion matrix to zeros every 5 loops\n",
    "    if datasetCounter % 5 == 0:\n",
    "        confusion_final = np.zeros((num_classes,num_classes))\n",
    "        \n",
    "    confusion_temp = np.zeros((num_classes,num_classes))\n",
    "    print('Prepare next chunk for training...', flush=True)\n",
    "    #train_set = datasetFromItList(itList=itList, batchsize=batchsize, num_classes=num_classes)\n",
    "    print(f'Training model on the current TF-Dataset (nr: {datasetCounter})', flush=True)\n",
    "    history = model.fit(train_set, validation_data=test_set, epochs=epochs, verbose=1, callbacks=[logger, saver]) \n",
    "\n",
    "    # CONFUSION MATRIX\n",
    "    Y_pred = model.predict(test_set)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    true_categories = tf.concat([y for _, y in test_set], axis=0)\n",
    "    np_testset = tfds.as_numpy(true_categories)\n",
    "    np_testset = np.argmax(np_testset, axis=1)\n",
    "    print('True_class argmax')\n",
    "    print(np_testset[0:chunksize])\n",
    "    print('Pred_class_argmax')\n",
    "    print(y_pred[0:chunksize])   \n",
    "    print('Confusion Matrix')\n",
    "    confusion_temp = confusion_matrix(y_pred=y_pred, y_true=np_testset)\n",
    "    confusion_final = (confusion_final + confusion_temp)\n",
    "    df_conf_mat = pd.DataFrame(confusion_final, columns=target_names, index=target_names)\n",
    "    # normalized confusion matrix\n",
    "    confusion_final_norm = np.around(confusion_final.astype('float') / confusion_final.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    df_conf_mat_norm = pd.DataFrame(confusion_final_norm, columns=target_names, index=target_names)\n",
    "    print(df_conf_mat_norm)\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(df_conf_mat_norm, annot=True, cmap=plt.cm.Blues)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "          \n",
    "    # Retrieve accuracy of this while loop for storing best weights\n",
    "    accuraciesOfThisLoop = history.history['accuracy']\n",
    "    valAccuraciesOfThisLoop = history.history['val_accuracy']\n",
    "    # Compare the accuarcy and valAcc of the last epoch with bestAccuracy      \n",
    "    idx = len(accuraciesOfThisLoop) - 1\n",
    "    print('Loop while number: %i; current bestAccuracy: %.2f; accuraciesOfThisLoop %.2f; valAccuraciesOfThisLoop: %.2f; acc - val_acc: %.2f.' % (\n",
    "        datasetCounter, bestAccuracy, accuraciesOfThisLoop[idx], valAccuraciesOfThisLoop[idx], (accuraciesOfThisLoop[idx] - valAccuraciesOfThisLoop[idx])\n",
    "    ))\n",
    "\n",
    "    if (bestAccuracy < accuraciesOfThisLoop[idx]) and ((accuraciesOfThisLoop[idx] - valAccuraciesOfThisLoop[idx]) < 0.1):\n",
    "        bestAccuracy = '{:.3f}'.format(round(valAccuraciesOfThisLoop[idx], 3))\n",
    "        bestAccuracy = float(bestAccuracy)\n",
    "        bestValAccuracy = '{:.3f}'.format(round(valAccuraciesOfThisLoop[idx], 3))\n",
    "        bestValAccuracy = float(bestValAccuracy)          \n",
    "        print('The weights are saved...')        \n",
    "        model.save_weights(f'{checkpointFolder}/weights.best.hdf5')\n",
    "        print('The confusion matrix is saved...')       \n",
    "        figure.savefig(f'{confMatFolder}/Conf_mat_valAcc_{str(bestValAccuracy)}.jpg', bbox_inches='tight')\n",
    "        print('\\n')\n",
    "    \n",
    "    datasetCounter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
