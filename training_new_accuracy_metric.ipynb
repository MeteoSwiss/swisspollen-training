{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5658a91-89ba-4951-b762-aa07f8c4631b",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"Swisens_logo.png\" width=\"240\" height=\"240\" align=\"left\"/>\n",
    "<div style=\"text-align: right\">\n",
    "    SwisensDataAnalyzer Introduction\n",
    "    <br>Machine Learning Model Training\n",
    "    <br>Author: <a href=\"mailto:yanick.zeder@swisens.ch\">Yanick Zeder</a>\n",
    "    <br> Copyright 2021, Swisens AG\n",
    "    <br> <a href=\"mailto:yanick.zeder@swisens.ch\"> Support </a>\n",
    "    <br><br>\n",
    "    <b>Adapted and modified by MeteoSwiss.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e131a44-c57c-47d0-914c-fc5b84acaf65",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training ConvNets\n",
    "\n",
    "## Known bugs\n",
    "- Swisens' data loading code sometimes crashes with error \"np.stack ValueError: need at least one array to stack\". Seems to happen only when few datasets are loaded (e.g. when loading only the spores collection).\n",
    "- EfficientNet suffers from a bug which makes it unable to be saved in TF2.10 ([source](https://discuss.tensorflow.org/t/using-efficientnetb0-and-save-model-will-result-unable-to-serialize-2-0896919-2-1128857-2-1081853-to-json-unrecognized-type-class-tensorflow-python-framework-ops-eagertensor/12518https://discuss.tensorflow.org/t/using-efficientnetb0-and-save-model-will-result-unable-to-serialize-2-0896919-2-1128857-2-1081853-to-json-unrecognized-type-class-tensorflow-python-framework-ops-eagertensor/12518))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f8217-c285-4703-98bb-1efacfc042c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93182008-bce1-4315-a513-4502d2cd59d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:49.269650Z",
     "iopub.status.busy": "2023-03-21T07:51:49.269249Z",
     "iopub.status.idle": "2023-03-21T07:51:49.274813Z",
     "shell.execute_reply": "2023-03-21T07:51:49.273598Z",
     "shell.execute_reply.started": "2023-03-21T07:51:49.269612Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\n",
    "    \"/tf/tmp/poleno-ml\"\n",
    ")\n",
    "sys.path.append(\n",
    "    \"/tf/tmp/poleno-db-interface/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cc27d3-074f-429e-895b-74c2bdbadd08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:49.276601Z",
     "iopub.status.busy": "2023-03-21T07:51:49.276338Z",
     "iopub.status.idle": "2023-03-21T07:51:53.705743Z",
     "shell.execute_reply": "2023-03-21T07:51:53.704295Z",
     "shell.execute_reply.started": "2023-03-21T07:51:49.276573Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /tf/tmp/poleno-ml\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: poleno-ml\n",
      "  Building wheel for poleno-ml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for poleno-ml: filename=poleno_ml-0.1.0-py3-none-any.whl size=16657 sha256=12d6271990170a322876efcca526be9de6d1d27bffe645254634e2242e715cc5\n",
      "  Stored in directory: /root/.cache/pip/wheels/36/27/94/c36c0ca182dfe6d14b2ad2190409db7ec462f251c1019d9266\n",
      "Successfully built poleno-ml\n",
      "Installing collected packages: poleno-ml\n",
      "  Attempting uninstall: poleno-ml\n",
      "    Found existing installation: poleno-ml 0.1.0\n",
      "    Uninstalling poleno-ml-0.1.0:\n",
      "      Successfully uninstalled poleno-ml-0.1.0\n",
      "Successfully installed poleno-ml-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# run this if you made changes to the poleno-ml code \n",
    "# NB: Those changes must have been made to the /tf/tmp/poleno-ml repository to have an effect on this notebook's code.\n",
    "# NB: However, changes made to the tmp repository are temporary and will be rolled back when Docker VM will be shutdown.\n",
    "#     If you want to make them permanent, dupplicate them to /tf/home/dependencies/poleno-ml.\n",
    "!pip install /tf/tmp/poleno-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b176c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:53.708729Z",
     "iopub.status.busy": "2023-03-21T07:51:53.708378Z",
     "iopub.status.idle": "2023-03-21T07:51:58.266295Z",
     "shell.execute_reply": "2023-03-21T07:51:58.265354Z",
     "shell.execute_reply.started": "2023-03-21T07:51:53.708692Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed for PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')\n",
      "Success for PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Success for PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "# Import all other necessary modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import cv2\n",
    "import datetime\n",
    "import io\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import operator\n",
    "import os\n",
    "import poleno_db_interface.database.model.data_explorer_model as dem\n",
    "import poleno_db_interface.database.model.poleno_data_model as pdm\n",
    "from poleno_ml.database.query_interface_ml import QueryInterfaceML, DatasetPipeline\n",
    "import random\n",
    "import sklearn.metrics\n",
    "from sqlalchemy import func\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras as keras\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List\n",
    "from uuid import UUID\n",
    "import uuid\n",
    "\n",
    "# allow memory growth\n",
    "for dev in tf.config.list_physical_devices():\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(\n",
    "            dev, True\n",
    "        )\n",
    "        print(f\"Success for {dev}\")\n",
    "    except:\n",
    "        print(f\"Failed for {dev}\")\n",
    "\n",
    "# specifies which PhysicalDevice objects are visible to the runtime. TF will only allocate memory and place operations on visible physical devices\n",
    "gpu0 = tf.config.list_physical_devices('GPU')[0] # use GPU n\n",
    "tf.config.set_visible_devices(gpu0, 'GPU')\n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "    gpu0, \n",
    "    #[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=25_000)] # set max GPU memory usage\n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=38_000)]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6187ed8f-3a3d-40d2-81db-596724043f06",
   "metadata": {},
   "source": [
    "# Using this strategy will place any variables created in its scope on the specified device. \n",
    "# Input distributed through this strategy will be prefetched to the specified device. \n",
    "# Moreover, any functions called via strategy.run will also be placed on the specified device as well.\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368125b3-7b29-4203-87e3-2790c3a44665",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Establishing a database connection <a class=\"anchor\" id=\"query\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2ff41d-1093-439c-897a-bd48a3d42399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.267676Z",
     "iopub.status.busy": "2023-03-21T07:51:58.267480Z",
     "iopub.status.idle": "2023-03-21T07:51:58.369025Z",
     "shell.execute_reply": "2023-03-21T07:51:58.368200Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.267655Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import myloginpath\n",
    "db_config = myloginpath.parse('client', path='/tf/.mylogin.cnf')\n",
    "\n",
    "# Conect to the database and create an interface instance\n",
    "query_interface_ml = QueryInterfaceML(**db_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558f7f7-6e73-4eba-bde1-eab47bf0022e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Defining the datasets and parameters to use <a class=\"anchor\" id=\"datasets\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74a808a8-8a88-4523-b88c-4abb9fcb86d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.370321Z",
     "iopub.status.busy": "2023-03-21T07:51:58.369933Z",
     "iopub.status.idle": "2023-03-21T07:51:58.413923Z",
     "shell.execute_reply": "2023-03-21T07:51:58.413083Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.370299Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A dictionary that has the form of { <collection>: { <dataset-id>: <class-label> } }\n",
    "# Collection name can be choosen freely and is intended to enable grouping of datasets into logical\n",
    "# units independnet on class. Typically, this can be used to seperate datasets form different systems\n",
    "# but can also be used to separate different years, sample source or any other propertie. Later in the\n",
    "# notebook, you will then be able to create test and validation sets with different collections as\n",
    "# source.\n",
    "DATASET_DEFINITIONS = {\n",
    "    \n",
    "    \"raw-pollens\": {\n",
    "        \"11ea8493-7107-8db4-9bf7-ae7b87f820b4\": \"Alnus\",\n",
    "        \"11ea847a-f995-790c-830f-ae7b87f820b4\": \"Alnus\",\n",
    "        \"11ea8475-957e-347c-985a-ae7b87f820b4\": \"Alnus\",\n",
    "        \"11ea8897-f50e-66a2-9876-ae7b87f820b4\": \"Betula\",\n",
    "        \"11ea8632-18ed-7210-985a-ae7b87f820b4\": \"Betula\",\n",
    "        \"11ea8632-1eb2-2452-bc84-ae7b87f820b4\": \"Betula\",\n",
    "        \"11ea8f77-4ee3-aef4-b330-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea8f6d-3e75-9fe6-b46e-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea8f6d-1562-211a-8192-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea8f6c-b78c-d076-a542-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea8498-b729-d4e6-bc84-ae7b87f820b4\": \"Corylus\",\n",
    "        \"11ea8498-b083-cb92-a1a5-ae7b87f820b4\": \"Corylus\",\n",
    "        \"11ea8498-afa9-cec4-a877-ae7b87f820b4\": \"Corylus\",\n",
    "        \"11ea8fa9-6c12-723a-b3dd-ae7b87f820b4\": \"Cupressus\",\n",
    "        \"11ea8fa8-fafa-aeb4-ac46-ae7b87f820b4\": \"Cupressus\",\n",
    "        \"11ea8fa8-d163-dce2-b1cb-ae7b87f820b4\": \"Cupressus\",\n",
    "        \"11ea8636-313b-a6e4-a69e-ae7b87f820b4\": \"Fagus\",\n",
    "        \"11ea8635-ef91-6ab2-a877-ae7b87f820b4\": \"Fagus\",\n",
    "        \"11ea8635-eb18-6ee0-9876-ae7b87f820b4\": \"Fagus\",\n",
    "        \"11ea857e-7bc5-60a0-842e-ae7b87f820b4\": \"Fraxinus\",\n",
    "        \"11ea857b-3d52-9034-830f-ae7b87f820b4\": \"Fraxinus\",\n",
    "        \"11ea857b-150e-c372-bc84-ae7b87f820b4\": \"Fraxinus\",\n",
    "        \"11ea8af3-c533-f39e-8b25-ae7b87f820b4\": \"Pinaceae\",\n",
    "        \"11ea8af1-91fc-9a46-8b25-ae7b87f820b4\": \"Pinaceae\",\n",
    "        \"11ea8af0-83dc-6d66-b06c-ae7b87f820b4\": \"Pinaceae\",\n",
    "        \"11ea863d-acf6-0ade-985a-ae7b87f820b4\": \"Pinaceae\",\n",
    "        \"11ea863c-2449-be52-8814-ae7b87f820b4\": \"Pinaceae\",\n",
    "        \"11ea8b83-25c9-8194-90d1-ae7b87f820b4\": \"Platanus\",\n",
    "        \"11ea8881-3721-9aa8-a907-ae7b87f820b4\": \"Platanus\",\n",
    "        \"11ea990f-ee01-8334-b3dd-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11ea990c-b2bc-fe96-b46e-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11eb5fd9-961a-313e-ac56-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11eb5fd9-dd36-0a20-88f3-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11ebe542-660e-0206-80be-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11eb5fc3-03fa-6da2-8b42-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11ebe540-187e-9a0c-b0e2-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11ea8893-edfb-ca84-a877-ae7b87f820b4\": \"Populus\",\n",
    "        \"11ea84a0-e89b-43b8-a69e-ae7b87f820b4\": \"Populus\",\n",
    "        \"11ea84a0-a2f0-ab8c-a877-ae7b87f820b4\": \"Populus\",\n",
    "        \"11ea863e-1fea-0f7c-a1a5-ae7b87f820b4\": \"Quercus\",\n",
    "        \"11ea863e-1b86-8226-a1a5-ae7b87f820b4\": \"Quercus\",\n",
    "        \"11ea863d-f388-a038-a1a5-ae7b87f820b4\": \"Quercus\",\n",
    "        \"11ea8477-cede-e7dc-897d-ae7b87f820b4\": \"Taxus\",\n",
    "        \"11ea8477-b584-b690-830f-ae7b87f820b4\": \"Taxus\",\n",
    "        \"11ea8494-33a5-2e4e-bc84-ae7b87f820b4\": \"Taxus\",\n",
    "        \"11ea849c-df8f-d95e-897d-ae7b87f820b4\": \"Ulmus\",\n",
    "        \"11ea849c-db7b-2170-8b0f-ae7b87f820b4\": \"Ulmus\",\n",
    "        \"11ea849a-0e25-4018-8814-ae7b87f820b4\": \"Ulmus\",\n",
    "    },\n",
    "    \n",
    "    \"old-pollens\": {\n",
    "        \"11ea5df1-de4e-68a2-bdea-ae7b87f820b4\": \"Alnus\",\n",
    "        \"11ea5dec-aad2-40f2-adc5-ae7b87f820b4\": \"Alnus\",\n",
    "        \"11ea5dea-76dd-45e6-9881-ae7b87f820b4\": \"Alnus\",\n",
    "        \"11ea8318-8f19-8414-8f2c-ae7b87f820b4\": \"Betula\",\n",
    "        \"11ea831d-c087-d5fa-8016-ae7b87f820b4\": \"Betula\",\n",
    "        \"11ea8319-0f9b-2f84-8f2c-ae7b87f820b4\": \"Betula\",\n",
    "        \"11ea74ee-1ae2-3f42-bdc8-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea74ef-1f33-22e0-b530-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea74ef-7256-f794-8624-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea74ef-cf63-afc2-bdc8-ae7b87f820b4\": \"Carpinus\",\n",
    "        \"11ea5e04-fc94-364e-81ab-ae7b87f820b4\": \"Corylus\",\n",
    "        \"11ea5e04-ae5b-1ace-9881-ae7b87f820b4\": \"Corylus\",\n",
    "        \"11ea5e00-93c5-6f88-81ab-ae7b87f820b4\": \"Corylus\",\n",
    "        \"11ea74e8-0f90-f08a-9ea9-ae7b87f820b4\": \"Cupressus\",\n",
    "        \"11ea74ea-1a2b-69ec-9846-ae7b87f820b4\": \"Cupressus\",\n",
    "        \"11ea74ea-93f3-4862-bc81-ae7b87f820b4\": \"Cupressus\",\n",
    "        \"11ea831e-9169-688c-9d84-ae7b87f820b4\": \"Fagus\",\n",
    "        \"11ea831e-5779-4480-a7e8-ae7b87f820b4\": \"Fagus\",\n",
    "        \"11ea831e-0698-1618-8016-ae7b87f820b4\": \"Fagus\",\n",
    "        \"11ea8314-3a9a-8644-8fc4-ae7b87f820b4\": \"Fraxinus\",\n",
    "        \"11ea8313-8fef-2358-8016-ae7b87f820b4\": \"Fraxinus\",\n",
    "        \"11ea8313-1742-26b2-9d84-ae7b87f820b4\": \"Fraxinus\",\n",
    "        \"11ea8af1-16b3-afbe-b419-ae7b87f820b4\": \"Pinaceae\", # Picea\n",
    "        \"11ea8af1-8668-a68e-b06c-ae7b87f820b4\": \"Pinaceae\", # Picea\n",
    "        \"11ea8af0-7bba-7a4c-9b82-ae7b87f820b4\": \"Pinaceae\", # Picea\n",
    "        \"11ea863b-0dbc-a204-8b0f-ae7b87f820b4\": \"Pinaceae\", # Pinus\n",
    "        \"11ea863c-0128-16ee-a69e-ae7b87f820b4\": \"Pinaceae\", # Pinus\n",
    "        \"11ea831f-8774-33e2-b44c-ae7b87f820b4\": \"Plantanus\",\n",
    "        \"11ea831f-3746-b084-a59a-ae7b87f820b4\": \"Plantanus\",\n",
    "        \"11ea990d-99b7-329e-b330-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11ea990c-a115-87c6-b46e-ae7b87f820b4\": \"Poaceae\",\n",
    "        \"11ea9a91-09a7-100e-86f2-ae7b87f820b4\": \"Poaceae\", # Cynosurus\n",
    "        \"11ea9a73-0d84-81ca-b3dd-ae7b87f820b4\": \"Poaceae\", # Cynosurus\n",
    "        \"11ebde5f-23d5-5e8c-8d93-ae7b87f820b4\": \"Poaceae\", # Dactylis\n",
    "        \"11ea9911-17a1-65b4-89a8-ae7b87f820b4\": \"Poaceae\", # Dactylis\n",
    "        \"11ebde60-40fb-4aa2-a536-ae7b87f820b4\": \"Poaceae\", # Trisetum\n",
    "        \"11ea830f-df57-8bdc-91a3-ae7b87f820b4\": \"Populus\",\n",
    "        \"11ea74e3-b2e6-df38-b530-ae7b87f820b4\": \"Populus\",\n",
    "        \"11ea74e4-5089-a266-8624-ae7b87f820b4\": \"Populus\",\n",
    "        \"11ea863a-bdae-8df4-a69e-ae7b87f820b4\": \"Quercus\",\n",
    "        \"11ea863a-2252-7b54-a1a5-ae7b87f820b4\": \"Quercus\",\n",
    "        \"11ea8639-acca-ee52-aa3e-ae7b87f820b4\": \"Quercus\",\n",
    "        \"11ea5deb-b5f0-b38e-9881-ae7b87f820b4\": \"Taxus\",\n",
    "        \"11ea5deb-6fa4-5f7a-bd51-ae7b87f820b4\": \"Taxus\",\n",
    "        \"11ea5df3-6b53-0252-adc5-ae7b87f820b4\": \"Taxus\",\n",
    "        \"11ea74d0-dd4c-4d34-9ea9-ae7b87f820b4\": \"Ulmus\",\n",
    "        \"11ea74cf-fc64-b108-8624-ae7b87f820b4\": \"Ulmus\",\n",
    "        \"11ea5ef1-f146-eabe-ab02-ae7b87f820b4\": \"Ulmus\",\n",
    "    },\n",
    "\n",
    "    #14 classes\n",
    "    \"new-pollens\": { # same datasets as in \"old-pollens\" but cleaned using a different strategy\n",
    "        \"11ed3b18-1ba8-ee6a-a8d4-496190c661df\": \"Alnus\",\n",
    "        \"11ed3821-9ab6-8dba-a8d4-496190c661df\": \"Alnus\",\n",
    "        \"11ed382b-542a-0dea-a8d4-496190c661df\": \"Alnus\",\n",
    "        \"11ed3832-b506-668e-a8d4-496190c661df\": \"Betula\",\n",
    "        \"11ed3a58-07b4-deb6-a8d4-496190c661df\": \"Betula\",\n",
    "        \"11ed38e1-b2f4-f996-a8d4-496190c661df\": \"Betula\",\n",
    "        \"11ed5ea4-96ed-bdf8-acbd-a95f70cb44b0\": \"Carpinus\",\n",
    "        \"11ed5f80-5dcc-9c24-acbd-a95f70cb44b0\": \"Carpinus\",\n",
    "        \"11ed3a6b-5612-556c-a8d4-496190c661df\": \"Carpinus\",\n",
    "        \"11ed3982-4837-efd6-a8d4-496190c661df\": \"Carpinus\",\n",
    "        \"11ed38e0-6bee-47ec-a8d4-496190c661df\": \"Corylus\",\n",
    "        \"11ed3a6f-f2ce-f140-a8d4-496190c661df\": \"Corylus\",\n",
    "        \"11ed431c-682d-5986-a8d4-496190c661df\": \"Corylus\",\n",
    "        \"11ed38ea-0973-6246-a8d4-496190c661df\": \"Cupressus\",\n",
    "        \"11ed3a79-1b42-92c2-a8d4-496190c661df\": \"Cupressus\",\n",
    "        \"11ed431e-c1e0-39ce-a8d4-496190c661df\": \"Cupressus\",\n",
    "        \"11ed3a7c-3218-626c-a8d4-496190c661df\": \"Fagus\",\n",
    "        \"11ed5f45-7fe1-e688-acbd-a95f70cb44b0\": \"Fagus\",\n",
    "        \"11ed5f7b-c645-a4b2-acbd-a95f70cb44b0\": \"Fagus\",\n",
    "        \"11ed3b22-8577-b13c-a8d4-496190c661df\": \"Fraxinus\",\n",
    "        \"11ed5f4a-52c3-34a4-acbd-a95f70cb44b0\": \"Fraxinus\",\n",
    "        \"11ed5f7e-c6f1-7f46-acbd-a95f70cb44b0\": \"Fraxinus\",\n",
    "        \"11ed3d7f-b12e-ad76-a8d4-496190c661df\": \"Pinaceae\", # Picea\n",
    "        \"11ed5f4d-49d0-5748-acbd-a95f70cb44b0\": \"Pinaceae\", # Picea\n",
    "        \"11ed5f82-2199-44da-acbd-a95f70cb44b0\": \"Pinaceae\", # Picea\n",
    "        \"11ed3d9b-7037-b6fc-a8d4-496190c661df\": \"Pinaceae\", # Pinus\n",
    "        \"11ed5494-ad56-7e64-acbd-a95f70cb44b0\": \"Pinaceae\", # Pinus\n",
    "        \"11ed5535-c71d-065a-acbd-a95f70cb44b0\": \"Pinaceae\", # Pinus\n",
    "        \"11ed55ce-5aaf-a2ae-acbd-a95f70cb44b0\": \"Pinaceae\", # Pinus\n",
    "        \"11ed55d0-cec8-bdae-acbd-a95f70cb44b0\": \"Pinaceae\", # Pinus\n",
    "        \"11ed55d5-a393-64c2-acbd-a95f70cb44b0\": \"Pinaceae\", # Pinus\n",
    "        \"11ed5907-4d09-f0b4-acbd-a95f70cb44b0\": \"Plantanus\",\n",
    "        \"11ed6006-a52a-2448-acbd-a95f70cb44b0\": \"Plantanus\",\n",
    "        \"11ed43d2-4043-b620-a8d4-496190c661df\": \"Poaceae\",\n",
    "        \"11ed6009-3e1d-3184-acbd-a95f70cb44b0\": \"Poaceae\",\n",
    "        \"11ed6030-3f50-655e-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed6035-488e-4564-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed6037-d194-cad4-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed6039-e772-8574-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed591a-064b-e868-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed591c-0732-bf5c-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed5922-9f70-fc56-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed5925-0949-93b6-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed5926-9845-1346-acbd-a95f70cb44b0\": \"Poaceae\", # Cynosurus\n",
    "        \"11ed6032-1974-ee34-acbd-a95f70cb44b0\": \"Poaceae\", # Dactylis\n",
    "        \"11ed6036-c877-51c0-acbd-a95f70cb44b0\": \"Poaceae\", # Dactylis\n",
    "        \"11ed603b-8b16-bcf8-acbd-a95f70cb44b0\": \"Poaceae\", # Dactylis\n",
    "        \"11ed6038-9eb8-c42a-acbd-a95f70cb44b0\": \"Poaceae\", # Dactylis\n",
    "        \"11ed6010-ad76-a770-acbd-a95f70cb44b0\": \"Poaceae\", # Dactylis\n",
    "        \"11ed4487-97ec-87e8-a8d4-496190c661df\": \"Poaceae\", # Trisetum\n",
    "        \"11ed5928-4b40-315a-acbd-a95f70cb44b0\": \"Populus\",\n",
    "        \"11ed6012-cffe-1c4a-acbd-a95f70cb44b0\": \"Populus\",\n",
    "        \"11ed6041-5f45-1876-acbd-a95f70cb44b0\": \"Populus\",\n",
    "        \"11ed5930-a266-322e-acbd-a95f70cb44b0\": \"Quercus\",\n",
    "        \"11ed601d-4f24-ca46-acbd-a95f70cb44b0\": \"Quercus\",\n",
    "        \"11ed6045-38bd-92ec-acbd-a95f70cb44b0\": \"Quercus\",\n",
    "        \"11ed59c8-6d52-bbaa-acbd-a95f70cb44b0\": \"Taxus\",\n",
    "        \"11ed602a-3932-49e0-acbd-a95f70cb44b0\": \"Taxus\",\n",
    "        \"11ed604c-7275-f1b2-acbd-a95f70cb44b0\": \"Taxus\",\n",
    "        \"11ed59ca-df2c-2188-acbd-a95f70cb44b0\": \"Ulmus\",\n",
    "        \"11ed602d-6874-225c-acbd-a95f70cb44b0\": \"Ulmus\",\n",
    "        \"11ed6048-9fb9-4b28-acbd-a95f70cb44b0\": \"Ulmus\",\n",
    "    },\n",
    "    \n",
    "    \"trash\": {\n",
    "        \"11eda79a-f000-b3a2-85ae-ae7b87f820b4\": \"Trash\",\n",
    "    },\n",
    "    \n",
    "    \"other\": {\n",
    "        \"11ed65b6-6a22-1968-b56b-ae7b87f820b4\": \"Artemisia\",\n",
    "        \"11ed463e-f09f-6456-b550-ae7b87f820b4\": \"Cedrus\",\n",
    "        \"11ec6179-fde0-042c-adac-ae7b87f820b4\": \"Iberulites\",\n",
    "        \"11ec617a-fb8b-e3f2-80fb-ae7b87f820b4\": \"Iberulites\",\n",
    "        \"11ec5821-b371-c3dc-8359-ae7b87f820b4\": \"Iberulites\",\n",
    "        \"11ec5832-4fee-03b4-8561-ae7b87f820b4\": \"Iberulites\",\n",
    "        \"11ebe542-f782-c172-bf10-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \"11ebeabd-e224-d5c4-8b63-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \"11ebedec-0da5-47ac-8066-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \"11ebee15-1fea-4c68-9cd6-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \n",
    "    },\n",
    "    \n",
    "    \"waterdroplets\":{\n",
    "        \"11ebe542-f782-c172-bf10-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \"11ebeabd-e224-d5c4-8b63-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \"11ebedec-0da5-47ac-8066-ae7b87f820b4\": \"Waterdroplets\",\n",
    "        \"11ebee15-1fea-4c68-9cd6-ae7b87f820b4\": \"Waterdroplets\",\n",
    "    },\n",
    "    \n",
    "    \"spores\": {\n",
    "        \"11ebf9db-f2e9-98cc-bc67-ae7b87f820b4\": \"Alternaria Solani\",\n",
    "        \"11ec01b9-d571-ea8e-b7e1-ae7b87f820b4\": \"Fusarium Graminearum\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d844c1-6637-4471-a841-e44a04568a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.414996Z",
     "iopub.status.busy": "2023-03-21T07:51:58.414804Z",
     "iopub.status.idle": "2023-03-21T07:51:58.447079Z",
     "shell.execute_reply": "2023-03-21T07:51:58.446385Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.414976Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'EffNET-B0_NEW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa66bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.448267Z",
     "iopub.status.busy": "2023-03-21T07:51:58.447852Z",
     "iopub.status.idle": "2023-03-21T07:51:58.479802Z",
     "shell.execute_reply": "2023-03-21T07:51:58.479054Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.448245Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 8 # the smaller, the more difficult the training becomes but it also generally means better generalization\n",
    "epochs = 256 # max number of epochs (early stopping automatically interrupts the training if validation loss stops improving)\n",
    "img_shape = (200,200,1)\n",
    "model_features = [\n",
    "     'rec0', 'rec1'  \n",
    "] # 'rec0' and 'rec1' for holo images\n",
    "data_filters = [\n",
    "    #'blur', # remove blurry events\n",
    "    #'crop', # remove cropped events\n",
    "]\n",
    "data_maps = [\n",
    "    #'process_waves', # remove \"waves\" from all events\n",
    "    #'holo_aug', # image augmentation\n",
    "] # if you change the training data, you might want to apply the same transformations to the polenos as pre-processing steps\n",
    "caching = True # whether or not cache the datasets locally for better performance\n",
    "\n",
    "collections_train = [\n",
    "    #\"raw-pollens\",\n",
    "    #\"old-pollens\",\n",
    "    \"new-pollens\",\n",
    "    #\"other\",\n",
    "    #\"spores\",\n",
    "    \"waterdroplets\",\n",
    "]\n",
    "\n",
    "# These two values only apply when collections_val is empty\n",
    "train_part = 0.8\n",
    "test_part = 0.2\n",
    "\n",
    "# Leave empty if you'd like to train and eval on the same collections\n",
    "collections_val = []\n",
    "\n",
    "classes = set(cls \n",
    "              for collection in collections_train + collections_val \n",
    "              for cls in DATASET_DEFINITIONS[collection].values()) # not need to touch this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de1ee9b7-b414-4d0e-a210-60c876339357",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.481874Z",
     "iopub.status.busy": "2023-03-21T07:51:58.481688Z",
     "iopub.status.idle": "2023-03-21T07:51:58.514822Z",
     "shell.execute_reply": "2023-03-21T07:51:58.513940Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.481855Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paths are created\n",
    "model_path = 'models'\n",
    "os.makedirs(os.path.join(model_path, model_name, \"training\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(model_path, model_name, \"model\"), exist_ok=True)\n",
    "ds_train_cache_path = os.path.join(model_path, model_name, 'training', f'train_cache_{\"_\".join(collections_train)}{\"_\" + \"_\".join(data_filters + data_maps) if len(data_filters + data_maps) > 0 else \"\"}')\n",
    "if len(collections_val) == 0:\n",
    "    cache_name = f'test_cache_{\"_\".join(collections_train)}'\n",
    "else:\n",
    "    cache_name = f'test_cache_{\"_\".join(collections_val)}'\n",
    "ds_val_cache_path = os.path.join(model_path, model_name, 'training', f'{cache_name}{\"_\" + \"_\".join(data_filters + data_maps) if len(data_filters + data_maps) > 0 else \"\"}')\n",
    "model_timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "checkpoint_file_path = os.path.join(model_path, model_name, 'training', 'checkpoints', model_timestamp)\n",
    "model_file_path = os.path.join(model_path, model_name, 'model')\n",
    "model_info_file_path = os.path.join(model_path, model_name, 'model', 'model_info.json')\n",
    "logdir = os.path.join(model_path, model_name, 'training', 'logs', model_timestamp)\n",
    "os.makedirs(logdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5958366-6d3f-42a5-b2db-4b7d8d6eb7af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.516430Z",
     "iopub.status.busy": "2023-03-21T07:51:58.516231Z",
     "iopub.status.idle": "2023-03-21T07:51:58.546669Z",
     "shell.execute_reply": "2023-03-21T07:51:58.545877Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.516410Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model's info to save on disk\n",
    "model_info = {\n",
    "    'model_name': model_name,\n",
    "    'model_timestamp': model_timestamp,\n",
    "    'batch_size': batch_size,\n",
    "    'model_features': model_features,\n",
    "    'data_filters': data_filters,\n",
    "    'data_maps': data_maps,\n",
    "    'collections_train': collections_train,\n",
    "    'train_part': train_part,\n",
    "    'test_part': test_part,\n",
    "    'collections_val': collections_val,\n",
    "    'DATASET_DEFINITIONS': DATASET_DEFINITIONS,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d074e54-8821-4cd9-99cc-32e73df216f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Computed Values\n",
    "Here we define the class weights for unbalanced datasets, the class counts, the class labels and we compute the model name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d693dd81-ded3-469e-ac9f-245e5f8525b9",
   "metadata": {},
   "source": [
    "First, we define some helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e24e7b74-6ca9-437d-bbdb-8b26ca07d9a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.547459Z",
     "iopub.status.busy": "2023-03-21T07:51:58.547272Z",
     "iopub.status.idle": "2023-03-21T07:51:58.580478Z",
     "shell.execute_reply": "2023-03-21T07:51:58.579764Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.547440Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_mapping(ds_map: dict, collections: List[str], classes: List[str]):\n",
    "    \"\"\"This method filters a dataset definition for specific systems and class labels\n",
    "    and returns a flat dictionary with { <dataset-id>: <class-label> } \"\"\"\n",
    "    \n",
    "    ret = {}\n",
    "    for c in collections:\n",
    "        ret.update(\n",
    "            { key: value for key, value in ds_map[c].items() if value in classes}\n",
    "        )\n",
    "    return ret\n",
    "\n",
    "def get_dataset_sizes(ds_map_flat: dict):\n",
    "    \"\"\"Return a dict with <dataset-id>: <class-size>\"\"\"\n",
    "    \n",
    "    dataset_sizes = {}\n",
    "    for k, v in dataset_map.items():\n",
    "        result = query_interface_ml.session.query(\n",
    "            func.count(dem.EventsInEventDataset.event_id)\n",
    "        ).filter(\n",
    "            dem.EventsInEventDataset.dataset_id==uuid.UUID(k).bytes\n",
    "        ).all()\n",
    "        dataset_sizes[k] = result[0][0]\n",
    "    return dataset_sizes\n",
    "    \n",
    "def get_class_sizes(ds_map_flat: dict, dataset_sizes: dict):\n",
    "    \"\"\"Return a dict with <class-name>: <class-size>\"\"\"\n",
    "    \n",
    "    class_sizes = {}\n",
    "    for k, v in dataset_map.items():\n",
    "        size = dataset_sizes[k]\n",
    "        if v not in class_sizes: class_sizes[v] = 0\n",
    "        class_sizes[v] += size\n",
    "    return class_sizes\n",
    "\n",
    "def get_sorted_class_list(ds_map_flat: dict):\n",
    "    return sorted(list(set(ds_map_flat.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c86d5aa-7390-4f1e-9efc-0a215708a2b7",
   "metadata": {},
   "source": [
    "... and then we can compute the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "599bc8ca-b765-4cd7-a647-76fe212866ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.581423Z",
     "iopub.status.busy": "2023-03-21T07:51:58.581233Z",
     "iopub.status.idle": "2023-03-21T07:51:58.724312Z",
     "shell.execute_reply": "2023-03-21T07:51:58.723617Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.581404Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the dataset collection you need for the training\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "dataset_map = get_dataset_mapping(\n",
    "    DATASET_DEFINITIONS,\n",
    "    collections=collections_train,\n",
    "    classes=classes\n",
    ")\n",
    "assert len(dataset_map) > 0\n",
    "\n",
    "dataset_sizes = get_dataset_sizes(dataset_map)\n",
    "class_sizes = get_class_sizes(dataset_map, dataset_sizes)\n",
    "classes = get_sorted_class_list(dataset_map)\n",
    "num_classes = len(classes)\n",
    "\n",
    "n_samples = sum(dataset_sizes.values())\n",
    "class_counts = [class_sizes[d] for d in classes]\n",
    "\n",
    "all_class_weights = n_samples / np.array(class_counts)\n",
    "class_weights = {0: all_class_weights[0]*2, 1: all_class_weights[1]*2, 2: all_class_weights[2],\n",
    "                 3: all_class_weights[3]*2, 4: all_class_weights[4], 5: all_class_weights[5]*2,\n",
    "                 6: all_class_weights[6]*2, 7: all_class_weights[7], 8: all_class_weights[8]*2,\n",
    "                 9: all_class_weights[9]*2, 10:all_class_weights[10], 11:all_class_weights[11]*2, \n",
    "                 12:all_class_weights[12], 13:all_class_weights[13], 14:all_class_weights[14]}\n",
    "\n",
    "model_info['classes'] = classes\n",
    "model_info['class_weights'] = list(class_weights.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd092e8-80f5-4e86-aef2-d62a8fb8dc89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup the dataset pipeline <a class=\"anchor\" id=\"pipeline\"></a>\n",
    "This step builds the dataset pipeline used later to train the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd01de7a-758e-4c86-acc3-1ab74d3e4fbf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17c78e34-d206-46fe-83d6-04e3443ed6a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:51:58.725321Z",
     "iopub.status.busy": "2023-03-21T07:51:58.725130Z",
     "iopub.status.idle": "2023-03-21T07:53:47.263453Z",
     "shell.execute_reply": "2023-03-21T07:53:47.262221Z",
     "shell.execute_reply.started": "2023-03-21T07:51:58.725302Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(collections_val) == 0:\n",
    "\n",
    "    dataset_train, dataset_val = query_interface_ml.prepare_tf_dataset_from_poleno_datasets(\n",
    "        dataset_list=list(dataset_map.keys()),\n",
    "        batch_size=batch_size,\n",
    "        model_features=model_features,\n",
    "        labels=classes,\n",
    "        dataset_label_mapping=dataset_map,\n",
    "        split=(train_part, test_part)\n",
    "    )\n",
    "\n",
    "else:\n",
    "    \n",
    "    dataset_map_val = get_dataset_mapping(\n",
    "        DATASET_DEFINITIONS,\n",
    "        collections=collections_val,\n",
    "        classes=classes\n",
    "    )\n",
    "    \n",
    "    dataset_train = query_interface_ml.prepare_tf_dataset_from_poleno_datasets(\n",
    "        dataset_list=list(dataset_map.keys()),\n",
    "        batch_size=batch_size,\n",
    "        model_features=model_features,\n",
    "        labels=classes,\n",
    "        dataset_label_mapping=dataset_map,\n",
    "    )\n",
    "    \n",
    "    dataset_val = query_interface_ml.prepare_tf_dataset_from_poleno_datasets(\n",
    "        dataset_list=list(dataset_map_val.keys()),\n",
    "        batch_size=batch_size,\n",
    "        model_features=model_features,\n",
    "        labels=classes,\n",
    "        dataset_label_mapping=dataset_map_val,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f649c94-4c3c-46bf-a48f-a3fe81fdb695",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Define then apply filters and maps (e.g. data augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f733876-810b-4c5d-a0e8-f1d750c5523c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:53:47.264924Z",
     "iopub.status.busy": "2023-03-21T07:53:47.264719Z",
     "iopub.status.idle": "2023-03-21T07:53:47.310019Z",
     "shell.execute_reply": "2023-03-21T07:53:47.308981Z",
     "shell.execute_reply.started": "2023-03-21T07:53:47.264903Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define data filters\n",
    "# filters out images where particles are cropped\n",
    "def filter_crop(rec0: tf.Tensor, rec1: tf.Tensor, T: float = .0001, BT: float = .85):\n",
    "    border = [0,rec0.shape[0]-1]\n",
    "    mask = np.array([\n",
    "        [1. if i in border or j in border else 0. for j in range(rec0.shape[1])]\n",
    "        for i in range(rec0.shape[0])\n",
    "    ]).reshape(*rec0.shape)\n",
    "    apply_filter_crop_ = lambda x: ((x.numpy()<BT)*mask).sum() / mask.sum() > T # return True if particle is cropped\n",
    "    return not apply_filter_crop_(rec0) and not apply_filter_crop_(rec1)\n",
    "apply_filter_crop = lambda ids, features, targets: tf.py_function( #py_function to work in eager mode (dataset operations are in graph mode by default)\n",
    "    filter_crop, [features['rec0'], features['rec1']], Tout=tf.bool\n",
    ")\n",
    "\n",
    "# filters out images where particles are blurry\n",
    "def filter_blur(rec0: tf.Tensor, rec1: tf.Tensor, T: float = .0014):\n",
    "    apply_filter_blur_ = lambda x: cv2.Laplacian(x.numpy(), cv2.CV_32F).var() < T # return True if image is blurred\n",
    "    return not apply_filter_blur_(rec0) and not apply_filter_blur_(rec1)\n",
    "apply_filter_blur = lambda ids, features, targets: tf.py_function( #py_function to work in eager mode (dataset operations are in graph mode by default)\n",
    "    filter_blur, [features['rec0'], features['rec1']], Tout=tf.bool\n",
    ")\n",
    "\n",
    "def filter_test(rec0: tf.Tensor, rec1: tf.Tensor):\n",
    "    apply_filter_test_ = lambda x: True\n",
    "    return not apply_filter_test_(rec0) and not apply_filter_test_(rec1)\n",
    "apply_filter_test = lambda ids, features, targets: tf.py_function( #py_function to work in eager mode (dataset operations are in graph mode by default)\n",
    "    filter_test, [features['rec0'], features['rec1']], Tout=tf.bool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "435b97ab-6010-4b06-8cbe-a134436069bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:53:47.311092Z",
     "iopub.status.busy": "2023-03-21T07:53:47.310900Z",
     "iopub.status.idle": "2023-03-21T07:53:47.346404Z",
     "shell.execute_reply": "2023-03-21T07:53:47.345556Z",
     "shell.execute_reply.started": "2023-03-21T07:53:47.311072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define data maps:\n",
    "# removes \"waves\" around the particles\n",
    "def rmv_waves(rec: tf.Tensor):\n",
    "    img = (rec.numpy()*255).astype(np.uint8)\n",
    "    img = img.reshape(*img.shape[:-1])\n",
    "    blurred = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    _, mask = cv2.threshold(blurred, 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    cleaned = img * ~(mask).astype(bool)\n",
    "    return cleaned\n",
    "\n",
    "# performs random image augmentation\n",
    "upper = 120 * (math.pi/180.0) # degrees -> radian\n",
    "lower = -120 * (math.pi/180.0)\n",
    "def rand_degree():\n",
    "    return random.uniform(lower, upper)\n",
    "def augment_using_ops(img: tf.Tensor):\n",
    "    try: img = tf.image.random_flip_left_right(img)\n",
    "    except: print(\"flip hori\")\n",
    "    try: img = tf.image.random_flip_up_down(img)\n",
    "    except: print(\"flip vert\")\n",
    "    try: img = tf.image.random_brightness(img, 0.1)\n",
    "    except: print(\"brightness\")\n",
    "    try: img = tf.image.random_contrast(img, 0.7, 1.3)\n",
    "    except: print(\"contrast\")\n",
    "    try: img = tfa.image.rotate(img, rand_degree(), fill_mode='nearest') # fill_mode='constant', fill_value=1.\n",
    "    except: print(\"rotate\")\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841c3ed4-3568-40c7-bca6-f21277e319d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:53:47.347467Z",
     "iopub.status.busy": "2023-03-21T07:53:47.347270Z",
     "iopub.status.idle": "2023-03-21T07:53:47.380752Z",
     "shell.execute_reply": "2023-03-21T07:53:47.379977Z",
     "shell.execute_reply.started": "2023-03-21T07:53:47.347447Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_custom_holo_map(func, *args):\n",
    "    func_ = lambda x: tf.reshape(\n",
    "        tf.convert_to_tensor(\n",
    "            tf.py_function(func, [x], Tout=[tf.float32]), \n",
    "            dtype=tf.float32),\n",
    "        img_shape)\n",
    "    args[1]['rec0'] = func_(args[1]['rec0'])\n",
    "    args[1]['rec1'] = func_(args[1]['rec1'])\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef37950a-3d1a-45dd-9164-6b9c00c8fcbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:53:47.381746Z",
     "iopub.status.busy": "2023-03-21T07:53:47.381553Z",
     "iopub.status.idle": "2023-03-21T07:53:47.425888Z",
     "shell.execute_reply": "2023-03-21T07:53:47.425177Z",
     "shell.execute_reply.started": "2023-03-21T07:53:47.381725Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# apply data filters and data maps\n",
    "dataset_train.tf_dataset = dataset_train.tf_dataset.unbatch()\n",
    "dataset_val.tf_dataset = dataset_val.tf_dataset.unbatch()\n",
    "\n",
    "if 'blur' in data_filters:\n",
    "    dataset_train.tf_dataset = dataset_train.tf_dataset.filter(apply_filter_blur)\n",
    "    dataset_val.tf_dataset = dataset_val.tf_dataset.filter(apply_filter_blur)\n",
    "if 'crop' in data_filters:\n",
    "    dataset_train.tf_dataset = dataset_train.tf_dataset.filter(apply_filter_crop)\n",
    "    dataset_val.tf_dataset = dataset_val.tf_dataset.filter(apply_filter_crop)\n",
    "if 'process_waves' in data_maps:\n",
    "    dataset_train.tf_dataset = dataset_train.tf_dataset.map(lambda *args: apply_custom_holo_map(rmv_waves, *args), num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    dataset_val.tf_dataset = dataset_val.tf_dataset.map(lambda *args: apply_custom_holo_map(rmv_waves, *args), num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "if 'holo_aug' in data_maps:\n",
    "    augmented_train = dataset_train.tf_dataset.map(lambda *args: apply_custom_holo_map(augment_using_ops, *args), num_parallel_calls=tf.data.AUTOTUNE, deterministic=False)\n",
    "    dataset_train.tf_dataset = dataset_train.tf_dataset.concatenate(augmented_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6babf2-bc38-4f81-aec7-ee91c98008e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Cache, shuffle, batch, and prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17a53246-2f33-4e79-bcb5-50d4c394d73e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:53:47.426900Z",
     "iopub.status.busy": "2023-03-21T07:53:47.426707Z",
     "iopub.status.idle": "2023-03-21T07:54:20.091858Z",
     "shell.execute_reply": "2023-03-21T07:54:20.090585Z",
     "shell.execute_reply.started": "2023-03-21T07:53:47.426880Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: Remember to remove the cache file if you make changes to the dataset! Otherwise, the changes will not be reflected into the dataset and the trainingwill run on the old data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1407140bf48740c68ceee26501243d03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing cache:   0%|          | 0/135424 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching is done.\n"
     ]
    }
   ],
   "source": [
    "# Cache the pipeline to a file in order to make subsequent training passes much faster\n",
    "if caching:\n",
    "    # Cache the pipeline to a file in order to make subsequent training passes much faster\n",
    "    dataset_train.enable_cache(ds_train_cache_path, prepare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1287110-dcec-4fec-9b19-a656338f472e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:20.093703Z",
     "iopub.status.busy": "2023-03-21T07:54:20.093345Z",
     "iopub.status.idle": "2023-03-21T07:54:28.952881Z",
     "shell.execute_reply": "2023-03-21T07:54:28.951982Z",
     "shell.execute_reply.started": "2023-03-21T07:54:20.093666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: Remember to remove the cache file if you make changes to the dataset! Otherwise, the changes will not be reflected into the dataset and the trainingwill run on the old data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing cache:   0%|          | 0/33856 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching is done.\n"
     ]
    }
   ],
   "source": [
    "if caching:\n",
    "    dataset_val.enable_cache(ds_val_cache_path, prepare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41bd43a7-b369-4466-9660-94a082c03a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:28.954370Z",
     "iopub.status.busy": "2023-03-21T07:54:28.954146Z",
     "iopub.status.idle": "2023-03-21T07:54:28.998520Z",
     "shell.execute_reply": "2023-03-21T07:54:28.997505Z",
     "shell.execute_reply.started": "2023-03-21T07:54:28.954349Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train.tf_dataset = dataset_train.tf_dataset.shuffle(batch_size*100).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "dataset_val.tf_dataset = dataset_val.tf_dataset.shuffle(batch_size*100, reshuffle_each_iteration=False).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9067a508-85a4-46c8-939e-b8349e3340bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-05T17:22:39.621895Z",
     "iopub.status.busy": "2022-12-05T17:22:39.621481Z",
     "iopub.status.idle": "2022-12-05T17:23:39.165824Z",
     "shell.execute_reply": "2022-12-05T17:23:39.164012Z",
     "shell.execute_reply.started": "2022-12-05T17:22:39.621855Z"
    },
    "tags": []
   },
   "source": [
    "# run this to get the real number of events in the datasets\n",
    "# note: this can take a long time and fill your ram if the dataset's too large\n",
    "'%i train, %i validation' % (len(list(dataset_train.tf_dataset.as_numpy_iterator())), len(list(dataset_val.tf_dataset.as_numpy_iterator())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84f9c892-3a63-4c8a-aa67-156c997fb9ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:28.999597Z",
     "iopub.status.busy": "2023-03-21T07:54:28.999399Z",
     "iopub.status.idle": "2023-03-21T07:54:29.036517Z",
     "shell.execute_reply": "2023-03-21T07:54:29.035667Z",
     "shell.execute_reply.started": "2023-03-21T07:54:28.999578Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset lengths: (train: 135424, val: 33856)\n",
      "number of classes: (train: 15, val: 15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"dataset lengths: (train: {dataset_train.dataset_length}, val: {dataset_val.dataset_length})\")\n",
    "print(f\"number of classes: (train: {dataset_train.num_classes}, val: {dataset_val.num_classes})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f7a1d-3969-4a0b-b1a1-0138599b9fb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Build the model <a class=\"anchor\" id=\"model\"></a>\n",
    "Now we can build the model we want to train. You can use any model as long as it has:\n",
    "- two inputs with the shape 200x200x1 with the names 'rec0' and 'rec1'\n",
    "- an output layer with the name 'target' and a dimension of #classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12da4f8-cee1-4d36-b39c-ef94b440cded",
   "metadata": {},
   "source": [
    "#### Operationnal model\n",
    "\n",
    "Use the model defined by Nina and Benoit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "453f4b72-244f-45b0-84e2-e5d9a2a9cede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:57:44.133525Z",
     "iopub.status.busy": "2023-02-14T08:57:44.133218Z",
     "iopub.status.idle": "2023-02-14T08:57:44.908513Z",
     "shell.execute_reply": "2023-02-14T08:57:44.906140Z",
     "shell.execute_reply.started": "2023-02-14T08:57:44.133491Z"
    },
    "tags": []
   },
   "source": [
    "inputs = []\n",
    "paths = []\n",
    "\n",
    "if \"rec0\" in model_features and \"rec1\" in model_features:\n",
    "    input0 = keras.layers.Input(shape=[200,200,1], name=\"rec0\")\n",
    "    inputs.append(input0)\n",
    "    input1 = keras.layers.Input(shape=[200,200,1], name=\"rec1\")\n",
    "    inputs.append(input1)\n",
    "\n",
    "    ###                                   -> VVVV <- Change here to B0 - B7 if needed.\n",
    "    path0 = keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(input0)\n",
    "    path0 = keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path0)\n",
    "    path0 = keras.layers.Dropout(0.2)(path0)\n",
    "    path0 = keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path0)\n",
    "    path0 = keras.layers.Dropout(0.2)(path0)\n",
    "    path0 = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path0)\n",
    "    path0 = keras.layers.Dropout(0.2)(path0)\n",
    "    path0 = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path0)\n",
    "    path0 = keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path0)\n",
    "    path0 = keras.layers.Dropout(0.2)(path0)\n",
    "\n",
    "    path1 = keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(input1)\n",
    "    path1 = keras.layers.Conv2D(64, (5,5), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path1)\n",
    "    path1 = keras.layers.Dropout(0.2)(path1)\n",
    "    path1 = keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.Conv2D(64, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.MaxPool2D(2, strides=(2,2),padding='same')(path1)\n",
    "    path1 = keras.layers.Dropout(0.2)(path1)\n",
    "    path1 = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.Conv2D(128, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path1)\n",
    "    path1 = keras.layers.Dropout(0.2)(path1)\n",
    "    path1 = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.Conv2D(256, (3,3), padding='same', activation='relu')(path1)\n",
    "    path1 = keras.layers.MaxPool2D((2,2), strides=(2,2),padding='same')(path1)\n",
    "    path1 = keras.layers.Dropout(0.2)(path1)\n",
    "\n",
    "    ### \n",
    "    holo_path_ = keras.layers.Flatten()(holo_path_)\n",
    "    holo_path_ = keras.layers.Concatenate()([path0, path1])\n",
    "    \n",
    "    \n",
    "    paths.append(holo_path_)\n",
    "\n",
    "if \"fl_spectra\" in model_features:\n",
    "    input_fl = keras.layers.Input(shape=[13], name=\"fl_spectra\")\n",
    "    fl_path = input_fl * 255\n",
    "    fl_path = keras.layers.Dense(255)(fl_path)\n",
    "    inputs.append(input_fl)\n",
    "    paths.append(fl_path)\n",
    "\n",
    "if len(paths) > 1:\n",
    "    path_ = keras.layers.Concatenate()(paths)\n",
    "else:\n",
    "    path_ = paths[0]\n",
    "\n",
    "path_ = tf.keras.layers.Dense(64)(path_)\n",
    "path_ = tf.keras.layers.Dropout(0.2)(path_)\n",
    "\n",
    "#path_ = keras.layers.Dropout(.2)(path_)\n",
    "outputs = keras.layers.Dense(\n",
    "    num_classes,\n",
    "    activation=\"softmax\",\n",
    "    name=\"target\"\n",
    ")(path_)\n",
    "#outputs = keras.layers.Softmax(name=\"target\")(outputs)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[outputs])\n",
    "\n",
    "\"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651abab8-ad5c-4f5a-bc37-25820cc06450",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Pre-trained EffNet\n",
    "This uses transfer learning in order to get faster results. You can choose between 8 models B0 - B7, each a little larger than the previous. The way this is set up is that we remove the final layer of the pretrained network and add our own output layer corresponding to our classes.\n",
    "\n",
    "Note that during our tests, B0 was sufficient for most applications. With larger models you increase the tendency to overfit the data. If you have many classes and large datasets, you can consider increasing the model size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aabb6de9-132b-4fb8-b235-b0f4bf8919eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:29.037600Z",
     "iopub.status.busy": "2023-03-21T07:54:29.037411Z",
     "iopub.status.idle": "2023-03-21T07:54:29.072951Z",
     "shell.execute_reply": "2023-03-21T07:54:29.072136Z",
     "shell.execute_reply.started": "2023-03-21T07:54:29.037581Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# WARNING: THIS IS NOT A GOOD IDEA TO DO IF YOU DOWNLOAD DATA FROM UNKNOW OR UNVERIFIED SOURCES !!!\n",
    "# THIS COULD INDUCE HUGE SECURITY RISKS.\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb3b9a73-c163-4e06-ac0e-4f9ca2717d88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:29.073984Z",
     "iopub.status.busy": "2023-03-21T07:54:29.073790Z",
     "iopub.status.idle": "2023-03-21T07:54:31.586137Z",
     "shell.execute_reply": "2023-03-21T07:54:31.585303Z",
     "shell.execute_reply.started": "2023-03-21T07:54:29.073964Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = []\n",
    "paths = []\n",
    "\n",
    "if \"rec0\" in model_features and \"rec1\" in model_features:\n",
    "    input0 = keras.layers.Input(shape=[200,200,1], name=\"rec0\")\n",
    "    inputs.append(input0)\n",
    "    input1 = keras.layers.Input(shape=[200,200,1], name=\"rec1\")\n",
    "    inputs.append(input1)\n",
    "\n",
    "    input0_reshape = keras.layers.Concatenate()([input0,input0,input0])\n",
    "    input1_reshape = keras.layers.Concatenate()([input1,input1,input1])\n",
    "    input0_reshape = input0_reshape * 255 # effnet expects [0, 255] data range\n",
    "    input1_reshape = input1_reshape * 255 # effnet expects [0, 255] data range\n",
    "\n",
    "    ###                                   -> VVVV <- Change here to B0 - B7 if needed.\n",
    "    effnetB0 = keras.applications.EfficientNetB0(input_shape=(200,200,3), \n",
    "                                                 drop_connect_rate=0.4, # extra regularization in finetuning, but does not affect loaded weights\n",
    "                                                 include_top=False,\n",
    "                                                 weights='imagenet')\n",
    "    effnetB0.trainable = False\n",
    "\n",
    "    path0 = effnetB0(input0_reshape)\n",
    "    path1 = effnetB0(input1_reshape)\n",
    "\n",
    "    holo_path_ = keras.layers.Concatenate()([path0, path1])\n",
    "    holo_path_ = keras.layers.Flatten()(holo_path_)\n",
    "    \n",
    "    paths.append(holo_path_)\n",
    "\n",
    "if \"fl_spectra\" in model_features:\n",
    "    input_fl = keras.layers.Input(shape=[13], name=\"fl_spectra\")\n",
    "    fl_path = input_fl * 255\n",
    "    fl_path = keras.layers.Dense(255)(fl_path)\n",
    "    inputs.append(input_fl)\n",
    "    paths.append(fl_path)\n",
    "\n",
    "if len(paths) > 1:\n",
    "    path_ = keras.layers.Concatenate()(paths)\n",
    "else:\n",
    "    path_ = paths[0]\n",
    "\n",
    "path_ = keras.layers.Dropout(.4)(path_)\n",
    "outputs = keras.layers.Dense(\n",
    "    num_classes,\n",
    "    activation=\"sigmoid\",\n",
    "    name=\"target\"\n",
    ")(path_)\n",
    "#outputs = keras.layers.Softmax(name=\"target\")(outputs)\n",
    "\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=[outputs])\n",
    "\n",
    "\"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfe34ce8-136a-4cb7-95c9-99252c6eeddd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:31.589426Z",
     "iopub.status.busy": "2023-03-21T07:54:31.589211Z",
     "iopub.status.idle": "2023-03-21T07:54:31.663721Z",
     "shell.execute_reply": "2023-03-21T07:54:31.662888Z",
     "shell.execute_reply.started": "2023-03-21T07:54:31.589404Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " rec0 (InputLayer)              [(None, 200, 200, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " rec1 (InputLayer)              [(None, 200, 200, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 200, 200, 3)  0           ['rec0[0][0]',                   \n",
      "                                                                  'rec0[0][0]',                   \n",
      "                                                                  'rec0[0][0]']                   \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 200, 200, 3)  0           ['rec1[0][0]',                   \n",
      "                                                                  'rec1[0][0]',                   \n",
      "                                                                  'rec1[0][0]']                   \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, 200, 200, 3)  0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLambda  (None, 200, 200, 3)  0          ['concatenate_1[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " efficientnetb0 (Functional)    (None, 7, 7, 1280)   4049571     ['tf.math.multiply[0][0]',       \n",
      "                                                                  'tf.math.multiply_1[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 7, 7, 2560)   0           ['efficientnetb0[0][0]',         \n",
      "                                                                  'efficientnetb0[1][0]']         \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 125440)       0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 125440)       0           ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " target (Dense)                 (None, 15)           1881615     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,931,186\n",
      "Trainable params: 1,881,615\n",
      "Non-trainable params: 4,049,571\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0409e34-5c77-44a4-b899-c9f696aa197e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compile the model\n",
    "By compiling we are adding the optimizer function and the loss function which drives the actual training. Usually, this can be left as is.\n",
    "\n",
    "If you notice that the model trains very slowly -> increase learning_rate <br>\n",
    "If the loss is fluctuating or rising -> decrease learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd3269b7-ffba-40d5-8201-176537e10f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:31.665003Z",
     "iopub.status.busy": "2023-03-21T07:54:31.664801Z",
     "iopub.status.idle": "2023-03-21T07:54:31.702877Z",
     "shell.execute_reply": "2023-03-21T07:54:31.702092Z",
     "shell.execute_reply.started": "2023-03-21T07:54:31.664982Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To compile the model, we need a special loss funtion that allows for class weights. The details are not that important. Relavent to know\n",
    "# is that this allows for inbalanced data to be trained correctly. For example, if you have two times more of class 1 than in class 2, then\n",
    "# you would like the model to ignore this difference and act as if the two sets are identical in size.\n",
    "\n",
    "class WeightedSCCE(tf.keras.losses.Loss):\n",
    "    \"\"\"Custom SparseCategoricalCrossentropy loss class that supports class weights.\"\"\"\n",
    "    def __init__(self, class_weight, from_logits=False, name='weighted_scce'):\n",
    "        if class_weight is None or all(v == 1. for v in class_weight):\n",
    "            self.class_weight = None\n",
    "        else:\n",
    "            self.class_weight = tf.convert_to_tensor(class_weight,\n",
    "                dtype=tf.float32)\n",
    "        self.reduction = keras.losses.Reduction.NONE\n",
    "        self.unreduced_scce = keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=from_logits, name=name,\n",
    "            reduction=self.reduction)\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, y_true, y_pred, sample_weight=None):\n",
    "        loss = self.unreduced_scce(y_true, y_pred, sample_weight)\n",
    "        if self.class_weight is not None:\n",
    "            weight_mask = tf.gather(self.class_weight, y_true)\n",
    "            loss = tf.math.multiply(loss, weight_mask)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cf0661e-3240-4e4f-8e24-aeac32f9caef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:31.703742Z",
     "iopub.status.busy": "2023-03-21T07:54:31.703550Z",
     "iopub.status.idle": "2023-03-21T07:54:31.751808Z",
     "shell.execute_reply": "2023-03-21T07:54:31.751037Z",
     "shell.execute_reply.started": "2023-03-21T07:54:31.703723Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally we compile the ml model\n",
    "learning_rate = 0.000_005\n",
    "model.compile(\n",
    "    # Optimizer, that handles the weight adjustment while training\n",
    "    optimizer=keras.optimizers.Adam(learning_rate),  \n",
    "    # Loss function to minimize\n",
    "    loss=WeightedSCCE(list(class_weights.values())),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fa6896-5250-443c-8897-d31bd389484e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setting up TensorBoard\n",
    "You can either access TensorBoard from the widgets below or by forwarding port 6006 to your localhost and access from your local browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af32a826-c31a-410b-aa73-64a058ed6172",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:31.752831Z",
     "iopub.status.busy": "2023-03-21T07:54:31.752637Z",
     "iopub.status.idle": "2023-03-21T07:54:31.788811Z",
     "shell.execute_reply": "2023-03-21T07:54:31.787942Z",
     "shell.execute_reply.started": "2023-03-21T07:54:31.752811Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "#%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "# https://stackoverflow.com/questions/40106949/unable-to-open-tensorboard-in-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7477158-7931-474d-b817-a232409f17de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:31.789789Z",
     "iopub.status.busy": "2023-03-21T07:54:31.789597Z",
     "iopub.status.idle": "2023-03-21T07:54:35.469205Z",
     "shell.execute_reply": "2023-03-21T07:54:35.467831Z",
     "shell.execute_reply.started": "2023-03-21T07:54:31.789770Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5f1b3b7add6f70ae\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5f1b3b7add6f70ae\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={logdir} --bind_all --port 6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde4d0bd-3d54-4cc7-93e4-f18281ccfe35",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train and export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81f2b7f7-0aa6-477f-8ad0-cfc20410f712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:35.470983Z",
     "iopub.status.busy": "2023-03-21T07:54:35.470691Z",
     "iopub.status.idle": "2023-03-21T07:54:35.535643Z",
     "shell.execute_reply": "2023-03-21T07:54:35.534694Z",
     "shell.execute_reply.started": "2023-03-21T07:54:35.470951Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confusion matrix plotting at each epoch in TensorBoard\n",
    "# source: https://towardsdatascience.com/exploring-confusion-matrix-evolution-on-tensorboard-e66b39f4ac12 by Surhrut Ashtikar, last visited on 28.11.2022\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "    \n",
    "    Args:\n",
    "       cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "       class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    # Normalize the confusion matrix.\n",
    "    cm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    ax.set(xticks=tick_marks,\n",
    "           yticks=tick_marks,\n",
    "           xticklabels=class_names, \n",
    "           yticklabels=class_names,\n",
    "           title='Confusion matrix',\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    #fig.tight_layout()\n",
    "    return fig\n",
    "    \n",
    "def plot_to_image(figure):\n",
    "    \"\"\"\n",
    "    Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "    returns it. The supplied figure is closed and inaccessible after this call.\n",
    "    \"\"\"\n",
    "    \n",
    "    buf = io.BytesIO()\n",
    "    \n",
    "    # Use plt.savefig to save the plot to a PNG in memory.\n",
    "    plt.savefig(buf, format='png')\n",
    "    \n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    plt.close(figure)\n",
    "    buf.seek(0)\n",
    "    \n",
    "    # Use tf.image.decode_png to convert the PNG buffer\n",
    "    # to a TF image. Make sure you use 4 channels.\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    \n",
    "    # Use tf.expand_dims to add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def log_confusion_matrix(epoch, logs):\n",
    "    \n",
    "    # Use the model to predict the values from the test_images.\n",
    "    val_pred_raw = model.predict(dataset_val.get_data_pipeline().prefetch(tf.data.AUTOTUNE))\n",
    "    \n",
    "    val_pred = np.argmax(val_pred_raw, axis=1)\n",
    "    \n",
    "    # Calculate the confusion matrix using sklearn.metrics\n",
    "    cm = sklearn.metrics.confusion_matrix(val_labels, val_pred)\n",
    "    \n",
    "    figure = plot_confusion_matrix(cm, class_names=classes)\n",
    "    cm_image = plot_to_image(figure)\n",
    "    \n",
    "    # Log the confusion matrix as an image summary.\n",
    "    with file_writer_cm.as_default():\n",
    "        tf.summary.image(\"Confusion Matrix\", cm_image, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cff1eeec-0a4d-4787-a5e3-1e235f529e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:35.537059Z",
     "iopub.status.busy": "2023-03-21T07:54:35.536785Z",
     "iopub.status.idle": "2023-03-21T07:54:41.713759Z",
     "shell.execute_reply": "2023-03-21T07:54:41.712484Z",
     "shell.execute_reply.started": "2023-03-21T07:54:35.537030Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4973876a5cd4d3ebbd65d29663203a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_labels = []  # store true labels\n",
    "for _, label_batch in tqdm(dataset_val.get_data_pipeline()): # iterate over the validation dataset\n",
    "    val_labels.extend(label_batch[\"target\"].numpy()) # append true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "213cae0f-976a-449c-a5e8-098d4490a618",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:41.715653Z",
     "iopub.status.busy": "2023-03-21T07:54:41.715340Z",
     "iopub.status.idle": "2023-03-21T07:54:41.777372Z",
     "shell.execute_reply": "2023-03-21T07:54:41.776124Z",
     "shell.execute_reply.started": "2023-03-21T07:54:41.715620Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init tensorflow callbacks\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_file_path, save_weights_only=True, save_best_only=True, monitor='val_loss', mode='min')\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78d7cbeb-d5a5-4c83-8b01-754d6c3f0da9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T07:54:41.778781Z",
     "iopub.status.busy": "2023-03-21T07:54:41.778498Z",
     "iopub.status.idle": "2023-03-21T19:13:51.545762Z",
     "shell.execute_reply": "2023-03-21T19:13:51.542879Z",
     "shell.execute_reply.started": "2023-03-21T07:54:41.778752Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "4232/4232 [==============================] - 109s 25ms/step\n",
      "16928/16928 [==============================] - 637s 37ms/step - loss: 26.0039 - sparse_categorical_accuracy: 0.6676 - val_loss: 16.0200 - val_sparse_categorical_accuracy: 0.8052\n",
      "Epoch 2/256\n",
      "4232/4232 [==============================] - 105s 25ms/step\n",
      "16928/16928 [==============================] - 620s 37ms/step - loss: 18.2668 - sparse_categorical_accuracy: 0.7744 - val_loss: 13.5337 - val_sparse_categorical_accuracy: 0.8277\n",
      "Epoch 3/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 628s 37ms/step - loss: 15.9321 - sparse_categorical_accuracy: 0.8028 - val_loss: 11.9045 - val_sparse_categorical_accuracy: 0.8583\n",
      "Epoch 4/256\n",
      "4232/4232 [==============================] - 102s 24ms/step\n",
      "16928/16928 [==============================] - 622s 37ms/step - loss: 14.6647 - sparse_categorical_accuracy: 0.8196 - val_loss: 11.5623 - val_sparse_categorical_accuracy: 0.8508\n",
      "Epoch 5/256\n",
      "4232/4232 [==============================] - 108s 26ms/step\n",
      "16928/16928 [==============================] - 616s 36ms/step - loss: 13.7274 - sparse_categorical_accuracy: 0.8312 - val_loss: 11.2912 - val_sparse_categorical_accuracy: 0.8524\n",
      "Epoch 6/256\n",
      "4232/4232 [==============================] - 105s 25ms/step\n",
      "16928/16928 [==============================] - 626s 37ms/step - loss: 13.0638 - sparse_categorical_accuracy: 0.8403 - val_loss: 10.4983 - val_sparse_categorical_accuracy: 0.8668\n",
      "Epoch 7/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 625s 37ms/step - loss: 12.5694 - sparse_categorical_accuracy: 0.8466 - val_loss: 9.8466 - val_sparse_categorical_accuracy: 0.8837\n",
      "Epoch 8/256\n",
      "4232/4232 [==============================] - 105s 25ms/step\n",
      "16928/16928 [==============================] - 623s 37ms/step - loss: 12.1228 - sparse_categorical_accuracy: 0.8517 - val_loss: 9.7408 - val_sparse_categorical_accuracy: 0.8783\n",
      "Epoch 9/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 643s 38ms/step - loss: 11.8046 - sparse_categorical_accuracy: 0.8563 - val_loss: 10.2223 - val_sparse_categorical_accuracy: 0.8681\n",
      "Epoch 10/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 633s 37ms/step - loss: 11.5079 - sparse_categorical_accuracy: 0.8594 - val_loss: 9.1110 - val_sparse_categorical_accuracy: 0.8928\n",
      "Epoch 11/256\n",
      "4232/4232 [==============================] - 113s 27ms/step\n",
      "16928/16928 [==============================] - 644s 38ms/step - loss: 11.2510 - sparse_categorical_accuracy: 0.8627 - val_loss: 9.1385 - val_sparse_categorical_accuracy: 0.8881\n",
      "Epoch 12/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 635s 38ms/step - loss: 11.0190 - sparse_categorical_accuracy: 0.8661 - val_loss: 9.6483 - val_sparse_categorical_accuracy: 0.8772\n",
      "Epoch 13/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 631s 37ms/step - loss: 10.8632 - sparse_categorical_accuracy: 0.8671 - val_loss: 9.0443 - val_sparse_categorical_accuracy: 0.8885\n",
      "Epoch 14/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 633s 37ms/step - loss: 10.6386 - sparse_categorical_accuracy: 0.8710 - val_loss: 9.1333 - val_sparse_categorical_accuracy: 0.8874\n",
      "Epoch 15/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 636s 38ms/step - loss: 10.5059 - sparse_categorical_accuracy: 0.8722 - val_loss: 9.1264 - val_sparse_categorical_accuracy: 0.8883\n",
      "Epoch 16/256\n",
      "4232/4232 [==============================] - 106s 25ms/step\n",
      "16928/16928 [==============================] - 643s 38ms/step - loss: 10.3130 - sparse_categorical_accuracy: 0.8736 - val_loss: 8.9781 - val_sparse_categorical_accuracy: 0.8899\n",
      "Epoch 17/256\n",
      "4232/4232 [==============================] - 112s 26ms/step\n",
      "16928/16928 [==============================] - 642s 38ms/step - loss: 10.2422 - sparse_categorical_accuracy: 0.8753 - val_loss: 8.5932 - val_sparse_categorical_accuracy: 0.8986\n",
      "Epoch 18/256\n",
      "4232/4232 [==============================] - 106s 25ms/step\n",
      "16928/16928 [==============================] - 641s 38ms/step - loss: 10.1192 - sparse_categorical_accuracy: 0.8771 - val_loss: 8.7856 - val_sparse_categorical_accuracy: 0.8921\n",
      "Epoch 19/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 637s 38ms/step - loss: 9.9211 - sparse_categorical_accuracy: 0.8795 - val_loss: 9.1790 - val_sparse_categorical_accuracy: 0.8764\n",
      "Epoch 20/256\n",
      "4232/4232 [==============================] - 108s 26ms/step\n",
      "16928/16928 [==============================] - 634s 37ms/step - loss: 9.7752 - sparse_categorical_accuracy: 0.8809 - val_loss: 8.6540 - val_sparse_categorical_accuracy: 0.8971\n",
      "Epoch 21/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 635s 37ms/step - loss: 9.8167 - sparse_categorical_accuracy: 0.8803 - val_loss: 8.4807 - val_sparse_categorical_accuracy: 0.9017\n",
      "Epoch 22/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 644s 38ms/step - loss: 9.6848 - sparse_categorical_accuracy: 0.8821 - val_loss: 8.5236 - val_sparse_categorical_accuracy: 0.9001\n",
      "Epoch 23/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 633s 37ms/step - loss: 9.6122 - sparse_categorical_accuracy: 0.8834 - val_loss: 8.2096 - val_sparse_categorical_accuracy: 0.9018\n",
      "Epoch 24/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 633s 37ms/step - loss: 9.5047 - sparse_categorical_accuracy: 0.8841 - val_loss: 8.1854 - val_sparse_categorical_accuracy: 0.9046\n",
      "Epoch 25/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 633s 37ms/step - loss: 9.4205 - sparse_categorical_accuracy: 0.8865 - val_loss: 8.2343 - val_sparse_categorical_accuracy: 0.8982\n",
      "Epoch 26/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 640s 38ms/step - loss: 9.3872 - sparse_categorical_accuracy: 0.8859 - val_loss: 8.2330 - val_sparse_categorical_accuracy: 0.9008\n",
      "Epoch 27/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 641s 38ms/step - loss: 9.2584 - sparse_categorical_accuracy: 0.8869 - val_loss: 8.1628 - val_sparse_categorical_accuracy: 0.8979\n",
      "Epoch 28/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 649s 38ms/step - loss: 9.2600 - sparse_categorical_accuracy: 0.8875 - val_loss: 8.3601 - val_sparse_categorical_accuracy: 0.8972\n",
      "Epoch 29/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 648s 38ms/step - loss: 9.2486 - sparse_categorical_accuracy: 0.8881 - val_loss: 8.1104 - val_sparse_categorical_accuracy: 0.9055\n",
      "Epoch 30/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 645s 38ms/step - loss: 9.1263 - sparse_categorical_accuracy: 0.8890 - val_loss: 8.1535 - val_sparse_categorical_accuracy: 0.9031\n",
      "Epoch 31/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 659s 39ms/step - loss: 9.0538 - sparse_categorical_accuracy: 0.8897 - val_loss: 8.3741 - val_sparse_categorical_accuracy: 0.8888\n",
      "Epoch 32/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 646s 38ms/step - loss: 9.0929 - sparse_categorical_accuracy: 0.8895 - val_loss: 8.1008 - val_sparse_categorical_accuracy: 0.8964\n",
      "Epoch 33/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 633s 37ms/step - loss: 8.9692 - sparse_categorical_accuracy: 0.8898 - val_loss: 8.6045 - val_sparse_categorical_accuracy: 0.8894\n",
      "Epoch 34/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 621s 37ms/step - loss: 8.9150 - sparse_categorical_accuracy: 0.8923 - val_loss: 8.2322 - val_sparse_categorical_accuracy: 0.9000\n",
      "Epoch 35/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 628s 37ms/step - loss: 8.8793 - sparse_categorical_accuracy: 0.8915 - val_loss: 8.3865 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 36/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 629s 37ms/step - loss: 8.8237 - sparse_categorical_accuracy: 0.8927 - val_loss: 8.1731 - val_sparse_categorical_accuracy: 0.8943\n",
      "Epoch 37/256\n",
      "4232/4232 [==============================] - 112s 26ms/step\n",
      "16928/16928 [==============================] - 634s 37ms/step - loss: 8.8763 - sparse_categorical_accuracy: 0.8925 - val_loss: 7.8551 - val_sparse_categorical_accuracy: 0.9036\n",
      "Epoch 38/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 627s 37ms/step - loss: 8.8264 - sparse_categorical_accuracy: 0.8928 - val_loss: 8.4189 - val_sparse_categorical_accuracy: 0.8887\n",
      "Epoch 39/256\n",
      "4232/4232 [==============================] - 108s 26ms/step\n",
      "16928/16928 [==============================] - 628s 37ms/step - loss: 8.8203 - sparse_categorical_accuracy: 0.8927 - val_loss: 8.3684 - val_sparse_categorical_accuracy: 0.8903\n",
      "Epoch 40/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 627s 37ms/step - loss: 8.7478 - sparse_categorical_accuracy: 0.8931 - val_loss: 8.0138 - val_sparse_categorical_accuracy: 0.9017\n",
      "Epoch 41/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 629s 37ms/step - loss: 8.6606 - sparse_categorical_accuracy: 0.8943 - val_loss: 7.8825 - val_sparse_categorical_accuracy: 0.9035\n",
      "Epoch 42/256\n",
      "4232/4232 [==============================] - 112s 26ms/step\n",
      "16928/16928 [==============================] - 651s 38ms/step - loss: 8.6014 - sparse_categorical_accuracy: 0.8947 - val_loss: 8.0951 - val_sparse_categorical_accuracy: 0.8997\n",
      "Epoch 43/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 636s 38ms/step - loss: 8.6202 - sparse_categorical_accuracy: 0.8943 - val_loss: 8.2528 - val_sparse_categorical_accuracy: 0.9023\n",
      "Epoch 44/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 632s 37ms/step - loss: 8.5809 - sparse_categorical_accuracy: 0.8951 - val_loss: 7.7850 - val_sparse_categorical_accuracy: 0.9050\n",
      "Epoch 45/256\n",
      "4232/4232 [==============================] - 109s 26ms/step\n",
      "16928/16928 [==============================] - 639s 38ms/step - loss: 8.5431 - sparse_categorical_accuracy: 0.8951 - val_loss: 7.7994 - val_sparse_categorical_accuracy: 0.9043\n",
      "Epoch 46/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 640s 38ms/step - loss: 8.5187 - sparse_categorical_accuracy: 0.8962 - val_loss: 7.8287 - val_sparse_categorical_accuracy: 0.9102\n",
      "Epoch 47/256\n",
      "4232/4232 [==============================] - 111s 26ms/step\n",
      "16928/16928 [==============================] - 631s 37ms/step - loss: 8.5374 - sparse_categorical_accuracy: 0.8960 - val_loss: 8.0058 - val_sparse_categorical_accuracy: 0.8974\n",
      "Epoch 48/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 625s 37ms/step - loss: 8.5118 - sparse_categorical_accuracy: 0.8963 - val_loss: 7.8423 - val_sparse_categorical_accuracy: 0.9025\n",
      "Epoch 49/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 653s 39ms/step - loss: 8.4726 - sparse_categorical_accuracy: 0.8968 - val_loss: 8.2181 - val_sparse_categorical_accuracy: 0.8890\n",
      "Epoch 50/256\n",
      "4232/4232 [==============================] - 108s 26ms/step\n",
      "16928/16928 [==============================] - 639s 38ms/step - loss: 8.4494 - sparse_categorical_accuracy: 0.8970 - val_loss: 8.1739 - val_sparse_categorical_accuracy: 0.8951\n",
      "Epoch 51/256\n",
      "4232/4232 [==============================] - 103s 24ms/step\n",
      "16928/16928 [==============================] - 643s 38ms/step - loss: 8.3740 - sparse_categorical_accuracy: 0.8972 - val_loss: 7.8099 - val_sparse_categorical_accuracy: 0.9115\n",
      "Epoch 52/256\n",
      "4232/4232 [==============================] - 108s 26ms/step\n",
      "16928/16928 [==============================] - 649s 38ms/step - loss: 8.4042 - sparse_categorical_accuracy: 0.8974 - val_loss: 8.9443 - val_sparse_categorical_accuracy: 0.8801\n",
      "Epoch 53/256\n",
      "4232/4232 [==============================] - 106s 25ms/step\n",
      "16928/16928 [==============================] - 642s 38ms/step - loss: 8.3693 - sparse_categorical_accuracy: 0.8978 - val_loss: 7.7801 - val_sparse_categorical_accuracy: 0.9072\n",
      "Epoch 54/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 638s 38ms/step - loss: 8.3901 - sparse_categorical_accuracy: 0.8973 - val_loss: 7.6566 - val_sparse_categorical_accuracy: 0.9058\n",
      "Epoch 55/256\n",
      "4232/4232 [==============================] - 110s 26ms/step\n",
      "16928/16928 [==============================] - 660s 39ms/step - loss: 8.3421 - sparse_categorical_accuracy: 0.8981 - val_loss: 7.9304 - val_sparse_categorical_accuracy: 0.8996\n",
      "Epoch 56/256\n",
      "4232/4232 [==============================] - 101s 24ms/step\n",
      "16928/16928 [==============================] - 645s 38ms/step - loss: 8.3329 - sparse_categorical_accuracy: 0.8984 - val_loss: 8.3811 - val_sparse_categorical_accuracy: 0.8957\n",
      "Epoch 57/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 648s 38ms/step - loss: 8.2978 - sparse_categorical_accuracy: 0.8981 - val_loss: 8.2794 - val_sparse_categorical_accuracy: 0.8948\n",
      "Epoch 58/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 639s 38ms/step - loss: 8.3433 - sparse_categorical_accuracy: 0.8980 - val_loss: 7.8804 - val_sparse_categorical_accuracy: 0.9078\n",
      "Epoch 59/256\n",
      "4232/4232 [==============================] - 107s 25ms/step\n",
      "16928/16928 [==============================] - 631s 37ms/step - loss: 8.3483 - sparse_categorical_accuracy: 0.8986 - val_loss: 8.0659 - val_sparse_categorical_accuracy: 0.8970\n",
      "Epoch 60/256\n",
      "4232/4232 [==============================] - 105s 25ms/step\n",
      "16928/16928 [==============================] - 629s 37ms/step - loss: 8.2771 - sparse_categorical_accuracy: 0.8979 - val_loss: 7.7325 - val_sparse_categorical_accuracy: 0.9011\n",
      "Epoch 61/256\n",
      "4232/4232 [==============================] - 104s 25ms/step\n",
      "16928/16928 [==============================] - 632s 37ms/step - loss: 8.2116 - sparse_categorical_accuracy: 0.8997 - val_loss: 8.3105 - val_sparse_categorical_accuracy: 0.8935\n",
      "Epoch 62/256\n",
      "4232/4232 [==============================] - 108s 25ms/step\n",
      "16928/16928 [==============================] - 647s 38ms/step - loss: 8.2464 - sparse_categorical_accuracy: 0.8992 - val_loss: 7.9431 - val_sparse_categorical_accuracy: 0.9014\n",
      "Epoch 63/256\n",
      "4232/4232 [==============================] - 105s 25ms/step\n",
      "16928/16928 [==============================] - 652s 38ms/step - loss: 8.2287 - sparse_categorical_accuracy: 0.9002 - val_loss: 8.0951 - val_sparse_categorical_accuracy: 0.8963\n",
      "Epoch 64/256\n",
      "4232/4232 [==============================] - 104s 25ms/step\n",
      "16928/16928 [==============================] - 632s 37ms/step - loss: 8.1959 - sparse_categorical_accuracy: 0.8996 - val_loss: 7.8542 - val_sparse_categorical_accuracy: 0.9121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcefc69f430>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    dataset_train.get_data_pipeline().prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=epochs, \n",
    "    validation_data=dataset_val.get_data_pipeline().prefetch(tf.data.AUTOTUNE),\n",
    "    callbacks=[\n",
    "        early_stopping, \n",
    "        checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        cm_callback\n",
    "    ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "958cd4c5-37b3-4ed7-b07a-670d495c32a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-21T19:13:51.549708Z",
     "iopub.status.busy": "2023-03-21T19:13:51.549465Z",
     "iopub.status.idle": "2023-03-21T19:14:36.344318Z",
     "shell.execute_reply": "2023-03-21T19:14:36.343116Z",
     "shell.execute_reply.started": "2023-03-21T19:13:51.549683Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 81). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/EffNET-B0_NEW/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/EffNET-B0_NEW/model/assets\n"
     ]
    }
   ],
   "source": [
    "# reload last checkpoint's weights those are the ones to export\n",
    "model.load_weights(checkpoint_file_path)\n",
    "# save the best model\n",
    "model.save(model_file_path)\n",
    "# save the model's essential info\n",
    "with open(model_info_file_path, 'w') as f:\n",
    "    f.write(json.dumps(model_info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9856a-173a-4860-a405-eedd6d3ce387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
