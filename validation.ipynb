{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc73e9e8-19a2-43ce-84e9-6597cfe6f81b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Time Series Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0348c511-046e-472b-86b9-1ddb98f1e197",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3e825e8-f9af-4284-a229-ce2e25205318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:48:40.160580Z",
     "iopub.status.busy": "2023-02-13T09:48:40.160134Z",
     "iopub.status.idle": "2023-02-13T09:48:44.864476Z",
     "shell.execute_reply": "2023-02-13T09:48:44.863587Z",
     "shell.execute_reply.started": "2023-02-13T09:48:40.160476Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /tf/tmp/poleno-ml\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: poleno-ml\n",
      "  Building wheel for poleno-ml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for poleno-ml: filename=poleno_ml-0.1.0-py3-none-any.whl size=16657 sha256=18352dcf69adc27224a808b475229d72d75b6b54a502d087cdefc8cdc285549c\n",
      "  Stored in directory: /root/.cache/pip/wheels/36/27/94/c36c0ca182dfe6d14b2ad2190409db7ec462f251c1019d9266\n",
      "Successfully built poleno-ml\n",
      "Installing collected packages: poleno-ml\n",
      "  Attempting uninstall: poleno-ml\n",
      "    Found existing installation: poleno-ml 0.1.0\n",
      "    Uninstalling poleno-ml-0.1.0:\n",
      "      Successfully uninstalled poleno-ml-0.1.0\n",
      "Successfully installed poleno-ml-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# run this if you made changes to the poleno-ml code \n",
    "# NB: Those changes must have been made to the /tf/tmp/poleno-ml repository to have an effect on this notebook's code.\n",
    "# NB: However, changes made to the tmp repository are temporary and will be rolled back when Docker VM will be shutdown.\n",
    "#     If you want to make them permanent, dupplicate them to /tf/home/dependencies/poleno-ml.\n",
    "!pip install /tf/tmp/poleno-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40e800f-c0ff-4152-877c-80aa230b8d94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:48:47.201533Z",
     "iopub.status.busy": "2023-02-13T09:48:47.201124Z",
     "iopub.status.idle": "2023-02-13T09:48:51.828973Z",
     "shell.execute_reply": "2023-02-13T09:48:51.827641Z",
     "shell.execute_reply.started": "2023-02-13T09:48:47.201497Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import copy\n",
    "import datetime\n",
    "from IPython.display import clear_output, display\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.pool import ThreadPool\n",
    "import numpy as np\n",
    "import operator as op\n",
    "import os\n",
    "import pandas as pd\n",
    "from poleno_db_interface.database.filter import AndClause, OrClause, ConditionClause, DataColumn\n",
    "from poleno_db_interface.database.query_utils import DataColumn, finalize_query\n",
    "from poleno_ml.database.query_interface_ml import QueryInterfaceML, DatasetPipeline\n",
    "import poleno_db_interface.database.model.poleno_data_model as pdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List\n",
    "from uuid import UUID\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140ea686-ba1a-4367-9605-ded8ca18f374",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:48:53.970258Z",
     "iopub.status.busy": "2023-02-13T09:48:53.969843Z",
     "iopub.status.idle": "2023-02-13T09:48:54.016766Z",
     "shell.execute_reply": "2023-02-13T09:48:54.015841Z",
     "shell.execute_reply.started": "2023-02-13T09:48:53.970224Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specifies which PhysicalDevice objects are visible to the runtime. TF will only allocate memory and place operations on visible physical devices\n",
    "#gpu0 = tf.config.list_physical_devices('GPU')[0] # use GPU 0\n",
    "#tf.config.set_visible_devices(gpu0, 'GPU')\n",
    "#tf.config.experimental.set_virtual_device_configuration(\n",
    "#    gpu0, \n",
    "#    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=35_000)] # set max GPU memory usage\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1ada55-c9f7-4733-8a8d-4c1aef768452",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fc6d8f5-ad12-42b1-b58c-1bc1475086f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:50:08.707021Z",
     "iopub.status.busy": "2023-02-13T09:50:08.706562Z",
     "iopub.status.idle": "2023-02-13T09:50:08.758756Z",
     "shell.execute_reply": "2023-02-13T09:50:08.757731Z",
     "shell.execute_reply.started": "2023-02-13T09:50:08.706980Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = '14Pol_Rain_10M_param_NEW'#'real2' # model you want to evaluate\n",
    "# pull poleno data between start_date and end_date measured by device_name\n",
    "start_date  = datetime.date(2020,2,19) # February 19th 2020\n",
    "end_date    = datetime.date(2020,1,8) # May 5th 2020\n",
    "device_name = 'poleno-5'\n",
    "# hirst data to compare against\n",
    "hirst_file_path = os.path.join('validation_input', 'hirst_pay_19022020-01112021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a61b8b6-8328-4044-b30f-4f9b82352169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:50:16.232907Z",
     "iopub.status.busy": "2023-02-13T09:50:16.232433Z",
     "iopub.status.idle": "2023-02-13T09:50:16.280644Z",
     "shell.execute_reply": "2023-02-13T09:50:16.279524Z",
     "shell.execute_reply.started": "2023-02-13T09:50:16.232872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_chunksize = 64\n",
    "pred_batch_size = 2048 # larger means faster prediction time but more memory consumption\n",
    "assert pred_batch_size >= db_chunksize, 'Predictions are way slower if pred_batch_size is smaller than db_chunksize.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed2da5-6123-4e7e-97a3-4f4cac664588",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c8fee81-6390-4a90-ab01-285b5554ef89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:50:17.789242Z",
     "iopub.status.busy": "2023-02-13T09:50:17.788855Z",
     "iopub.status.idle": "2023-02-13T09:50:17.837560Z",
     "shell.execute_reply": "2023-02-13T09:50:17.836625Z",
     "shell.execute_reply.started": "2023-02-13T09:50:17.789210Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare file paths\n",
    "model_path = os.path.join('models', model_name, 'model')\n",
    "model_info_file_path = os.path.join(model_path, 'model_info.json')\n",
    "eval_cache_path = os.path.join('validation_input', f'cache_{device_name}_{start_date}-{end_date}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f002e4dc-1ff6-445a-ab75-ff3203636926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:50:19.544433Z",
     "iopub.status.busy": "2023-02-13T09:50:19.544049Z",
     "iopub.status.idle": "2023-02-13T09:50:19.591187Z",
     "shell.execute_reply": "2023-02-13T09:50:19.590170Z",
     "shell.execute_reply.started": "2023-02-13T09:50:19.544401Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/14Pol_Rain_10M_param_NEW/model\n"
     ]
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.listdir()\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33eaf4e8-b5e4-4242-9c3f-6bb088a43f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:50:35.587884Z",
     "iopub.status.busy": "2023-02-13T09:50:35.587411Z",
     "iopub.status.idle": "2023-02-13T09:50:39.958346Z",
     "shell.execute_reply": "2023-02-13T09:50:39.957166Z",
     "shell.execute_reply.started": "2023-02-13T09:50:35.587849Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load trained model's info\n",
    "with open(model_info_file_path, 'r') as f:\n",
    "    model_info = json.loads(f.read())\n",
    "# load trained model\n",
    "model = keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8701c41d-6388-43db-bb57-166f5ab86975",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T09:50:44.347505Z",
     "iopub.status.busy": "2023-02-13T09:50:44.347173Z",
     "iopub.status.idle": "2023-02-13T09:50:44.391112Z",
     "shell.execute_reply": "2023-02-13T09:50:44.389980Z",
     "shell.execute_reply.started": "2023-02-13T09:50:44.347478Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_dir = os.path.join('models', model_info['model_name'], 'eval')\n",
    "os.makedirs(eval_dir, exist_ok=True)\n",
    "poleno_file_path = os.path.join(eval_dir, f'{device_name}_{start_date.strftime(\"%d%m%Y\")}-{end_date.strftime(\"%d%m%Y\")}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdef443-c331-405d-9ecd-e4474bb96490",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get the new model's predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab1ba39-bd10-484c-862c-2cdb794dc8c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Pull raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "74595c44-b6d2-4c5b-a53c-106ef991e26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T23:47:22.467597Z",
     "iopub.status.busy": "2023-01-31T23:47:22.467164Z",
     "iopub.status.idle": "2023-01-31T23:47:22.713016Z",
     "shell.execute_reply": "2023-01-31T23:47:22.712106Z",
     "shell.execute_reply.started": "2023-01-31T23:47:22.467560Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import myloginpath\n",
    "db_config = myloginpath.parse('client', path='/tf/.mylogin.cnf')\n",
    "\n",
    "# Conect to the database and create an interface instance\n",
    "query_interface_ml = QueryInterfaceML(**db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "2c314a9a-9a14-4143-8f98-6ab42e2224da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T23:47:23.900771Z",
     "iopub.status.busy": "2023-01-31T23:47:23.900437Z",
     "iopub.status.idle": "2023-02-01T00:12:29.377874Z",
     "shell.execute_reply": "2023-02-01T00:12:29.377133Z",
     "shell.execute_reply.started": "2023-01-31T23:47:23.900741Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " received 1187000unique evet list finished. Calling prepare_tf_dataset function 4.570105864606917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1187200"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load poleno's raw data measured during timerange\n",
    "filter_ = AndClause(\n",
    "    ConditionClause(pdm.Event.timestamp, op.gt, time.mktime(start_date.timetuple())),\n",
    "    ConditionClause(pdm.Event.timestamp, op.lt, time.mktime(end_date.timetuple())),\n",
    "    ConditionClause(pdm.Event.device_id_str, op.eq, device_name),\n",
    "    ConditionClause(pdm.ImageAnalysis.particleArea, op.ge, 625, \"img0\"),\n",
    "    ConditionClause(pdm.ImageAnalysis.particleArea, op.ge, 625, \"img1\"),\n",
    "    ConditionClause(pdm.ImageAnalysis.particleSolidity, op.ge, 0.9, \"img0\"),\n",
    "    ConditionClause(pdm.ImageAnalysis.particleSolidity, op.ge, 0.9, \"img1\"),\n",
    "    ConditionClause(pdm.ImageAnalysis.ImageData_id, op.eq, 0, \"img0\"),\n",
    "    ConditionClause(pdm.ImageAnalysis.ImageData_id, op.eq, 1, \"img1\"),\n",
    ")\n",
    "\n",
    "timeseries_dataset = query_interface_ml.prepare_tf_dataset_from_event_filter(\n",
    "    filter_=filter_,\n",
    "    batch_size=model_info['batch_size'],\n",
    "    model_features=copy.deepcopy(model_info['model_features']),\n",
    "    include_timestamps=True,\n",
    "    db_chunksize=db_chunksize\n",
    ")\n",
    "timeseries_dataset.dataset_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "85e89534-0b5f-4e5a-bc51-6cceb23c71ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T00:12:29.379343Z",
     "iopub.status.busy": "2023-02-01T00:12:29.379122Z",
     "iopub.status.idle": "2023-02-01T15:03:00.391565Z",
     "shell.execute_reply": "2023-02-01T15:03:00.389987Z",
     "shell.execute_reply.started": "2023-02-01T00:12:29.379321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTENTION: Remember to remove the cache file if you make changes to the dataset! Otherwise, the changes will not be reflected into the dataset and the trainingwill run on the old data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb698c2c30343aaa938052d05eed3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preparing cache:   0%|          | 0/1187200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching is done.\n"
     ]
    }
   ],
   "source": [
    "# cache the data\n",
    "timeseries_dataset.enable_cache(eval_cache_path, prepare=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "be6c7e96-7d07-4e02-ade2-6a18cd44c805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T22:09:46.414006Z",
     "iopub.status.busy": "2023-02-01T22:09:46.413534Z",
     "iopub.status.idle": "2023-02-01T22:09:46.509414Z",
     "shell.execute_reply": "2023-02-01T22:09:46.508354Z",
     "shell.execute_reply.started": "2023-02-01T22:09:46.413955Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batch and prefetch\n",
    "timeseries_dataset.tf_dataset = timeseries_dataset.tf_dataset.unbatch().batch(pred_batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ed4b03-18af-49a7-9b42-e07d814c8556",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "6bc3c8e7-d33c-42bf-a944-64a450d86109",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T22:09:48.859743Z",
     "iopub.status.busy": "2023-02-01T22:09:48.859353Z",
     "iopub.status.idle": "2023-02-01T22:28:04.062356Z",
     "shell.execute_reply": "2023-02-01T22:28:04.061416Z",
     "shell.execute_reply.started": "2023-02-01T22:09:48.859710Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/579 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the model's predictions for each event\n",
    "labels = np.array(model_info['classes'])\n",
    "list_batch_preds = []\n",
    "\n",
    "for id_batch, feature_batch in tqdm(timeseries_dataset.get_data_pipeline(with_id=True), \n",
    "                                    total=timeseries_dataset.dataset_length//pred_batch_size, leave=False):\n",
    "    try:\n",
    "        # compute predictions\n",
    "        preds = model.predict(feature_batch, verbose=False)\n",
    "    except ValueError: # this is for backward compatibility with the old model's architecture\n",
    "        feature_batch['input_1'] = feature_batch.pop('rec0')\n",
    "        feature_batch['input_2'] = feature_batch.pop('rec1')\n",
    "        # compute predictions\n",
    "        preds = model.predict(feature_batch, verbose=False)\n",
    "    # append predicted labels and certainty\n",
    "    y_pred = np.argmax(preds, axis=-1)\n",
    "    certainties = np.max(preds, axis=-1)\n",
    "    pred_classes = labels[y_pred]\n",
    "    list_batch_preds.append(pd.DataFrame({\n",
    "        'event_id': [id_.decode() for id_ in id_batch[\"id\"].numpy()],\n",
    "        'pred_class': pred_classes,\n",
    "        'pred_certainty': certainties,\n",
    "        'event_timestamp': [ts_ for ts_ in id_batch[\"timestamp\"].numpy()]\n",
    "    }))\n",
    "df_poleno = pd.concat(list_batch_preds).reset_index(drop=True) # convert list of pd.DataFrame to one pd.DataFrame\n",
    "del list_batch_preds\n",
    "# convert timestamp from double to datetime\n",
    "df_poleno['event_timestamp'] = df_poleno['event_timestamp'].apply(float)\n",
    "df_poleno['event_timestamp'] = pd.to_datetime(df_poleno['event_timestamp'], unit=\"s\")\n",
    "# set datetime as index\n",
    "df_poleno.index = df_poleno.event_timestamp\n",
    "df_poleno = df_poleno.drop(['event_timestamp'], axis=1)\n",
    "df_poleno.to_csv(poleno_file_path) # save to csv"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09a92dc8-4cce-4bfe-a6f9-1953d69f257f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-21T10:29:53.139000Z",
     "iopub.status.busy": "2022-12-21T10:29:53.138528Z",
     "iopub.status.idle": "2022-12-21T10:39:57.415090Z",
     "shell.execute_reply": "2022-12-21T10:39:57.411981Z",
     "shell.execute_reply.started": "2022-12-21T10:29:53.138960Z"
    },
    "tags": []
   },
   "source": [
    "# concurrent code isn't faster than the sequential version: I guess calls to the model's predict method are sequential either way.\n",
    "\n",
    "# get the model's predictions for each event\n",
    "labels = np.array(model_info['classes'])\n",
    "\n",
    "def concurrent_predict_(args):\n",
    "    id_batch, feature_batch = args\n",
    "    #feature_batch['input_1'] = feature_batch.pop('rec0') # only uncomment this if you need backward compatibility with the old model's architecture\n",
    "    #feature_batch['input_2'] = feature_batch.pop('rec1') # only uncomment this if you need backward compatibility with the old model's architecture\n",
    "    # compute predictions\n",
    "    preds = model.predict(feature_batch, verbose=False)\n",
    "    # append predicted labels and certainty\n",
    "    y_pred = np.argmax(preds, axis=-1)\n",
    "    certainties = np.max(preds, axis=-1)\n",
    "    pred_classes = labels[y_pred]\n",
    "    return pd.DataFrame({\n",
    "        'event_id': [id_.decode() for id_ in id_batch[\"id\"].numpy()],\n",
    "        'pred_class': pred_classes,\n",
    "        'pred_certainty': certainties,\n",
    "        'event_timestamp': [ts_ for ts_ in id_batch[\"timestamp\"].numpy()]\n",
    "    })\n",
    "# concurrently retrieve model's prediction for each event\n",
    "with ThreadPool(32) as pool:\n",
    "    list_batch_preds = list(tqdm(pool.imap(lambda args: concurrent_predict_(args), timeseries_dataset.get_data_pipeline(with_id=True)), \n",
    "                                 leave=False, total=timeseries_dataset.dataset_length // pred_batch_size))\n",
    "            \n",
    "df_poleno = pd.concat(list_batch_preds).reset_index(drop=True) # convert list of pd.DataFrame to one pd.DataFrame\n",
    "del list_batch_preds\n",
    "# convert timestamp from double to datetime\n",
    "df_poleno['event_timestamp'] = df_poleno['event_timestamp'].apply(float)\n",
    "df_poleno['event_timestamp'] = pd.to_datetime(df_poleno['event_timestamp'], unit=\"s\")\n",
    "df_poleno.index = df_poleno.event_timestamp\n",
    "df_poleno = df_poleno.drop(['event_timestamp'], axis=1)\n",
    "df_poleno.to_csv(poleno_file_path) # save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3094ef24-0642-4b03-85bf-2000ef706977",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T22:35:37.033234Z",
     "iopub.status.busy": "2023-02-01T22:35:37.032716Z",
     "iopub.status.idle": "2023-02-01T22:35:37.093390Z",
     "shell.execute_reply": "2023-02-01T22:35:37.092271Z",
     "shell.execute_reply.started": "2023-02-01T22:35:37.033167Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_interface_ml.session.rollback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d541124-5940-43c9-80d8-4767a067fb77",
   "metadata": {},
   "source": [
    "### Load previously created predictions file\n",
    "If you already ran the code above to generate predictions for your model, run this code to load the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "98b40a89-dc9b-44ab-8000-715d5355470b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:03.666655Z",
     "iopub.status.busy": "2023-02-01T23:07:03.666196Z",
     "iopub.status.idle": "2023-02-01T23:07:06.141677Z",
     "shell.execute_reply": "2023-02-01T23:07:06.140442Z",
     "shell.execute_reply.started": "2023-02-01T23:07:03.666615Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_poleno = pd.read_csv(poleno_file_path, index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e21048a-6371-4694-ae37-60ebaf47b67a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get Hirst data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "0f31bba8-6e0b-46aa-86e5-4b9ea60ab823",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:07.338680Z",
     "iopub.status.busy": "2023-02-01T23:07:07.338181Z",
     "iopub.status.idle": "2023-02-01T23:07:07.437968Z",
     "shell.execute_reply": "2023-02-01T23:07:07.436940Z",
     "shell.execute_reply.started": "2023-02-01T23:07:07.338637Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cupressus</th>\n",
       "      <th>Taxus</th>\n",
       "      <th>Alnus</th>\n",
       "      <th>Betula</th>\n",
       "      <th>Carpinus</th>\n",
       "      <th>Corylus</th>\n",
       "      <th>Fagus</th>\n",
       "      <th>Fraxinus</th>\n",
       "      <th>Pinaceae</th>\n",
       "      <th>Populus</th>\n",
       "      <th>Quercus</th>\n",
       "      <th>Ulmus</th>\n",
       "      <th>Poaceae</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-02-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Cupressus  Taxus  Alnus  Betula  Carpinus  Corylus  Fagus  \\\n",
       "event_timestamp                                                              \n",
       "2020-02-01             NaN    NaN    NaN     NaN       NaN      NaN    NaN   \n",
       "2020-02-02             NaN    NaN    NaN     NaN       NaN      NaN    NaN   \n",
       "2020-02-03             NaN    NaN    NaN     NaN       NaN      NaN    NaN   \n",
       "\n",
       "                 Fraxinus  Pinaceae  Populus  Quercus  Ulmus  Poaceae  \n",
       "event_timestamp                                                        \n",
       "2020-02-01            NaN       NaN      NaN      NaN    NaN      NaN  \n",
       "2020-02-02            NaN       NaN      NaN      NaN    NaN      NaN  \n",
       "2020-02-03            NaN       NaN      NaN      NaN    NaN      NaN  "
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hirst = pd.read_csv(hirst_file_path)\n",
    "timestamp_cols = ['Year', 'Month', 'Day', 'Hour', 'Minute']\n",
    "df_hirst['event_timestamp'] = pd.to_datetime(df_hirst[timestamp_cols])\n",
    "df_hirst = df_hirst.drop(timestamp_cols, axis=1)\n",
    "df_hirst = df_hirst.replace(32767, np.nan)\n",
    "df_hirst.index = df_hirst.event_timestamp\n",
    "df_hirst = df_hirst[[c for c in df_hirst.columns if c in list(model_info['classes'])]]\n",
    "df_hirst.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c969baa-11e7-4ecb-a1fc-2d136d886ee1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a292bad-e318-4d56-8415-f80480d9c413",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "522dd7d3-0865-47b6-a766-453ebfae7313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:09.001449Z",
     "iopub.status.busy": "2023-02-01T23:07:09.001039Z",
     "iopub.status.idle": "2023-02-01T23:07:09.060761Z",
     "shell.execute_reply": "2023-02-01T23:07:09.059579Z",
     "shell.execute_reply.started": "2023-02-01T23:07:09.001415Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_poleno_to_ts_(df_poleno, taxa, threshold, agg_freq):\n",
    "    df_poleno_to_plot = df_poleno[(df_poleno.pred_class == taxa) & (df_poleno.pred_certainty > threshold)].rename(columns={'event_id': 'poleno'})\n",
    "    df_poleno_to_plot = df_poleno_to_plot.resample(agg_freq).count() # frequency conversion and resampling of time series\n",
    "    if df_poleno_to_plot.shape[0] <= 0: # if no event have been found, create \"empty\" time series\n",
    "        ix_ = pd.period_range(df_poleno.index.min(), df_poleno.index.max(), freq='1D')\n",
    "        df_poleno_to_plot = pd.DataFrame({'poleno': np.zeros(len(ix_))}, index=ix_)\n",
    "        df_poleno_to_plot.index.rename('event_timestamp', inplace=True)\n",
    "    return df_poleno_to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "20fd7f1d-3a64-4fa9-9050-fabdc6855b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:09.216245Z",
     "iopub.status.busy": "2023-02-01T23:07:09.215838Z",
     "iopub.status.idle": "2023-02-01T23:07:09.266676Z",
     "shell.execute_reply": "2023-02-01T23:07:09.265476Z",
     "shell.execute_reply.started": "2023-02-01T23:07:09.216212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ts_and_merge_(df_poleno, df_hirst, taxa, threshold, agg_freq, scaling=False, date_range=None):\n",
    "    # poleno\n",
    "    df_poleno_ts = df_poleno_to_ts_(df_poleno, taxa, threshold, agg_freq)\n",
    "        \n",
    "    # hirst\n",
    "    df_hirst_ts = pd.DataFrame({'hirst': df_hirst[taxa].resample(agg_freq).sum()})\n",
    "    \n",
    "    # merged # LIG: added sort=True as sometimes order gets messed up with 'outer' -> bug??\n",
    "    timeseries = df_poleno_ts.merge(df_hirst_ts, on='event_timestamp', how='outer', sort=True)[['hirst','poleno']]\n",
    "    \n",
    "    if date_range is not None:\n",
    "        timeseries = timeseries[date_range[0]:date_range[1]]    \n",
    "    \n",
    "    factor=1.0 # LIG: create variable if no scaling\n",
    "    if scaling & (timeseries['hirst'].mean() >0) & (timeseries['poleno'].mean() > 0): #LIG: do not scale if 0 concentration\n",
    "        factor = timeseries['hirst'].mean() / timeseries['poleno'].mean()\n",
    "        timeseries['poleno'] *= factor\n",
    "    \n",
    "    \n",
    "    return timeseries, factor # LIG: add scaling-factor to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "33f2dc59-c2fc-4a46-a9b7-dfca3c8fe3e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:09.411656Z",
     "iopub.status.busy": "2023-02-01T23:07:09.411307Z",
     "iopub.status.idle": "2023-02-01T23:07:09.459987Z",
     "shell.execute_reply": "2023-02-01T23:07:09.458851Z",
     "shell.execute_reply.started": "2023-02-01T23:07:09.411625Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_(df_poleno: pd.DataFrame, df_hirst: pd.DataFrame, date_range: List[pd._libs.tslibs.timestamps.Timestamp], taxa: str, agg_freq: str, threshold: float, scaling: bool):\n",
    "    matplotlib.style.use('ggplot')\n",
    "\n",
    "    timeseries, factor = get_ts_and_merge_(df_poleno, df_hirst, taxa, threshold, agg_freq, scaling=scaling, date_range=date_range)\n",
    "    \n",
    "    print('Correlation: %.2f' % timeseries.corr().poleno.hirst)\n",
    "    print('scaling factor: %.2f' % factor) #LIG: show scaling factor\n",
    "    \n",
    "    fig = timeseries.plot(figsize=(12,4), title=taxa, ylabel='concentration')\n",
    "    fig.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "427b1810-3417-4c08-b8a1-fb529b50f3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:09.586299Z",
     "iopub.status.busy": "2023-02-01T23:07:09.585946Z",
     "iopub.status.idle": "2023-02-01T23:07:09.654335Z",
     "shell.execute_reply": "2023-02-01T23:07:09.653220Z",
     "shell.execute_reply.started": "2023-02-01T23:07:09.586268Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_widget(df_poleno: pd.DataFrame, df_hirst: pd.DataFrame):\n",
    "    # output widget\n",
    "    out = widgets.Output(layout = widgets.Layout(height='450px', overflow_y='auto'))\n",
    "    # ---\n",
    "\n",
    "    # dates range\n",
    "    #start_date = min(df_poleno.index.min(), df_hirst.index.min())\n",
    "    #end_date = max(df_poleno.index.max(), df_hirst.index.max())\n",
    "    \n",
    "    # LIG: limit range to where both are available:\n",
    "    start_date = max(df_poleno.index.min(), df_hirst.index.min()).floor('D')\n",
    "    end_date = min(df_poleno.index.max(), df_hirst.index.max()).ceil('D')\n",
    "    \n",
    "    dates = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "    options = [(date.strftime('%d.%m.%Y'), date) for date in dates]\n",
    "    index = (0, len(options)-1)\n",
    "\n",
    "    date_range_selector = widgets.SelectionRangeSlider(\n",
    "        options=options,\n",
    "        index=index,\n",
    "        description='Dates range',\n",
    "        orientation='horizontal',\n",
    "        layout={'width': '700px'},\n",
    "        readout=False\n",
    "    )\n",
    "    date_range_display = widgets.HTML(\n",
    "        value=(\n",
    "            f\"<b>{dates[index[0]]}\" + \n",
    "            f\" - {dates[index[1]]}</b>\"))\n",
    "\n",
    "    # Define the date range using the widgets.HBox\n",
    "    date_range = widgets.VBox(\n",
    "        (date_range_selector, date_range_display))\n",
    "\n",
    "    # Callback function that updates the display\n",
    "    def callback_daterange_(dts):\n",
    "        date_range_display.value = f\"<b>{dts[0].strftime('%d-%m-%Y')} - {dts[1].strftime('%d-%m-%Y')}</b>\"\n",
    "\n",
    "    widgets.interactive_output(\n",
    "        callback_daterange_, \n",
    "        {\"dts\": date_range_selector})\n",
    "    # ---\n",
    "    \n",
    "    # aggregation frequency\n",
    "    agg_freq_input = widgets.Text(\n",
    "        value='1D',\n",
    "        description='Aggregation frequency:',\n",
    "        disabled=False\n",
    "    )\n",
    "    agg_freq_display = widgets.HTML(value=('List of frequency strings <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#dateoffset-objects\">here</a>.'))\n",
    "    agg_freq = widgets.VBox(\n",
    "        (agg_freq_input, agg_freq_display))\n",
    "    # ---\n",
    "    \n",
    "    # taxa selection\n",
    "    taxa_to_plot = sorted([t for t in model_info['classes'] if t in df_hirst.columns])\n",
    "    taxa_selector = widgets.Dropdown(\n",
    "        options=taxa_to_plot,\n",
    "        value=taxa_to_plot[0],\n",
    "        description='Taxa:',\n",
    "    )\n",
    "    # ---\n",
    "    \n",
    "    # threshold\n",
    "    thresh_selector = widgets.BoundedFloatText(\n",
    "        value=.85,\n",
    "        min=.0,\n",
    "        max=1.,\n",
    "        step=0.05,\n",
    "        description='Threshold:',\n",
    "        disabled=False\n",
    "    )\n",
    "    # ---\n",
    "    \n",
    "    # enable/disable re-scaling\n",
    "    scaling_selector = widgets.Checkbox(\n",
    "        value=True,\n",
    "        description='Scale Poleno on Hirst',\n",
    "        disabled=False,\n",
    "        indent=False\n",
    "    )\n",
    "    # ---\n",
    "\n",
    "    # display button\n",
    "    btn_display = widgets.Button(description='display')\n",
    "    def on_click(_):\n",
    "        # \"linking function with output\"\n",
    "        with out:\n",
    "            # what happens when we press the button\n",
    "            clear_output()\n",
    "            plot_(df_poleno, df_hirst, date_range_selector.value, taxa_selector.value, agg_freq_input.value, thresh_selector.value, scaling_selector.value)\n",
    "            plt.show()\n",
    "            print(date_range_selector.value)\n",
    "    # linking button and function together using a button's method\n",
    "    btn_display.on_click(on_click)\n",
    "    # ---\n",
    "    return date_range, agg_freq, taxa_selector, thresh_selector, scaling_selector, btn_display, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f2e560ad-c03d-4144-a85d-364dd4c5f5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:09.781532Z",
     "iopub.status.busy": "2023-02-01T23:07:09.781105Z",
     "iopub.status.idle": "2023-02-01T23:07:09.831093Z",
     "shell.execute_reply": "2023-02-01T23:07:09.830144Z",
     "shell.execute_reply.started": "2023-02-01T23:07:09.781498Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rolling_win_corr(timeseries, win_size, punish_fp_threshold=None) -> np.array:\n",
    "    # if mean concentration of a specific pollen during a time period is < punish_fp_threshold : \n",
    "    # then double the correlation weight between hirst and predictions for this time period\n",
    "    corr, weights = [], []\n",
    "    gb = timeseries.resample(win_size) # group by week or any other time period\n",
    "    for x in gb.groups: # for each time period\n",
    "        x_i = gb.get_group(x)\n",
    "        corr.append(x_i.corr().poleno.hirst) # compute correlation\n",
    "        w_i = 1. if punish_fp_threshold is None or x_i['hirst'].mean() > punish_fp_threshold else 2. # compute weight\n",
    "        weights.append(w_i)\n",
    "    ma = np.ma.MaskedArray(corr, mask=np.isnan(corr)) # mask to ignore nan\n",
    "    weighted_avg = np.ma.average(ma, weights=weights)\n",
    "    return weighted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6e748162-21b9-4463-a863-ebb27da09db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:09.950946Z",
     "iopub.status.busy": "2023-02-01T23:07:09.950630Z",
     "iopub.status.idle": "2023-02-01T23:07:09.998109Z",
     "shell.execute_reply": "2023-02-01T23:07:09.997071Z",
     "shell.execute_reply.started": "2023-02-01T23:07:09.950916Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compare_ts(df_poleno, df_hirst, thresholds=None, agg_freq='1D', trunccorr_win_size='2W', punish_fp_threshold=None):\n",
    "    # LIG: finding all taxa occuring in the model and in the hirst data: they have to have the same name (hirst file and model_info.json)\n",
    "    joint_taxa = sorted([t for t in model_info['classes'] if t in df_hirst.columns])\n",
    "    if thresholds is None:\n",
    "        # LIG: set thresholds to 0 for all taxa\n",
    "        thresholds = {t: .0 for t in joint_taxa}\n",
    "    metrics = pd.DataFrame(index=joint_taxa, columns=['Pairwise Correlation', \n",
    "                                                      'Truncated Pairwise Correlation'], dtype=float)\n",
    "    for taxa in joint_taxa:\n",
    "        #timeseries = get_ts_and_merge_(df_poleno, df_hirst, taxa, threshold, agg_freq, scaling=False)\n",
    "        # LIG: the above line did not work: threshold not existant. line below works so far..\n",
    "        timeseries, factor = get_ts_and_merge_(df_poleno, df_hirst, taxa, thresholds[taxa], agg_freq, scaling=False) \n",
    "        metrics.at[taxa, 'Pairwise Correlation'] = timeseries.corr().poleno.hirst\n",
    "        metrics.at[taxa, 'Truncated Pairwise Correlation'] = rolling_win_corr(timeseries, trunccorr_win_size, punish_fp_threshold)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "d8c35692-38ac-46a3-afaa-4d30550e46b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:10.153583Z",
     "iopub.status.busy": "2023-02-01T23:07:10.153257Z",
     "iopub.status.idle": "2023-02-01T23:07:12.897703Z",
     "shell.execute_reply": "2023-02-01T23:07:12.896959Z",
     "shell.execute_reply.started": "2023-02-01T23:07:10.153553Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics = compare_ts(df_poleno, df_hirst, trunccorr_win_size='1W', punish_fp_threshold=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d427c0-107a-4b41-ae6d-2b1af9b6f3cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Actual plot widget and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "068818d4-92d1-4c03-9a79-d77899b75c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:13.905679Z",
     "iopub.status.busy": "2023-02-01T23:07:13.905261Z",
     "iopub.status.idle": "2023-02-01T23:07:17.058517Z",
     "shell.execute_reply": "2023-02-01T23:07:17.057461Z",
     "shell.execute_reply.started": "2023-02-01T23:07:13.905642Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Correlation\n",
      "Mean: 0.53, Median: 0.59, Min/Max: -0.08 (Taxus)/0.98 (s)\n",
      "\n",
      " Betula\n",
      "Truncated Pairwise Correlation\n",
      "Mean: 0.42, Median: 0.37, Min/Max: 0.19 (Corylus)/0.60 (s)\n",
      "\n",
      " Betula\n"
     ]
    }
   ],
   "source": [
    "# compute and print metrics values\n",
    "metrics = compare_ts(df_poleno, df_hirst, trunccorr_win_size='1W', punish_fp_threshold=None)\n",
    "for m in metrics:\n",
    "    print(m)\n",
    "    print('Mean: %.2f, Median: %.2f, Min/Max: %.2f (%s)/%.2f (s)\\n\\n' % (metrics[m].mean(), metrics[m].median(), metrics[m].min(), metrics.index[metrics[m].argmin()], metrics[m].max()), metrics.index[metrics[m].argmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "14242b0c-3490-4b5a-bf57-476f90d898bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:17.715607Z",
     "iopub.status.busy": "2023-02-01T23:07:17.714947Z",
     "iopub.status.idle": "2023-02-01T23:07:17.779635Z",
     "shell.execute_reply": "2023-02-01T23:07:17.778497Z",
     "shell.execute_reply.started": "2023-02-01T23:07:17.715557Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df_hirst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e9fd70ae-9a0d-4246-bc3c-0fdf428002c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-01T23:07:19.360763Z",
     "iopub.status.busy": "2023-02-01T23:07:19.360370Z",
     "iopub.status.idle": "2023-02-01T23:07:19.499452Z",
     "shell.execute_reply": "2023-02-01T23:07:19.498467Z",
     "shell.execute_reply.started": "2023-02-01T23:07:19.360731Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a9292c77214527abdbc78dac06d26e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(SelectionRangeSlider(description='Dates range', index=(0, 95), layout=Layout(widâ€¦"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display widget\n",
    "widgets.VBox(create_widget(df_poleno, df_hirst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ce981e-f58c-4b7b-8681-baa4574d9e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce514ffc-f3b7-4c5a-8fef-8a410c1ec39c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
